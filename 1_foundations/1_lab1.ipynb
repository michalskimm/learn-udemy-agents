{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marekca/learn/learn-udemy-agents/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If 5 machines take 5 minutes to make 5 widgets, how long would 100 machines take to make 100 widgets?\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the problem step-by-step:\n",
      "\n",
      "- **Given:**  \n",
      "  5 machines take 5 minutes to make 5 widgets.\n",
      "\n",
      "- **Step 1: Find the production rate per machine**  \n",
      "  If 5 machines make 5 widgets in 5 minutes, then in 5 minutes, 5 machines → 5 widgets.\n",
      "\n",
      "  Therefore, the rate for 1 machine in 5 minutes is:  \n",
      "  \\( \\frac{5 \\text{ widgets}}{5 \\text{ machines}} = 1 \\text{ widget per machine in 5 minutes} \\)\n",
      "\n",
      "- **Step 2: Find the rate per machine per minute**  \n",
      "  Since 1 machine makes 1 widget in 5 minutes, it makes:  \n",
      "  \\( \\frac{1}{5} \\) widget per minute.\n",
      "\n",
      "- **Step 3: Find how long 100 machines take to make 100 widgets**  \n",
      "  - Total widgets needed: 100.  \n",
      "  - Production rate for 100 machines is:  \n",
      "    \\( 100 \\times \\frac{1}{5} = 20 \\) widgets per minute.\n",
      "\n",
      "  - Time to make 100 widgets at 20 widgets per minute:  \n",
      "    \\( \\frac{100}{20} = 5 \\) minutes.\n",
      "\n",
      "**Answer:** 100 machines will take **5 minutes** to make 100 widgets.\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's analyze the problem step-by-step:\n",
       "\n",
       "- **Given:**  \n",
       "  5 machines take 5 minutes to make 5 widgets.\n",
       "\n",
       "- **Step 1: Find the production rate per machine**  \n",
       "  If 5 machines make 5 widgets in 5 minutes, then in 5 minutes, 5 machines → 5 widgets.\n",
       "\n",
       "  Therefore, the rate for 1 machine in 5 minutes is:  \n",
       "  \\( \\frac{5 \\text{ widgets}}{5 \\text{ machines}} = 1 \\text{ widget per machine in 5 minutes} \\)\n",
       "\n",
       "- **Step 2: Find the rate per machine per minute**  \n",
       "  Since 1 machine makes 1 widget in 5 minutes, it makes:  \n",
       "  \\( \\frac{1}{5} \\) widget per minute.\n",
       "\n",
       "- **Step 3: Find how long 100 machines take to make 100 widgets**  \n",
       "  - Total widgets needed: 100.  \n",
       "  - Production rate for 100 machines is:  \n",
       "    \\( 100 \\times \\frac{1}{5} = 20 \\) widgets per minute.\n",
       "\n",
       "  - Time to make 100 widgets at 20 widgets per minute:  \n",
       "    \\( \\frac{100}{20} = 5 \\) minutes.\n",
       "\n",
       "**Answer:** 100 machines will take **5 minutes** to make 100 widgets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended area: Autonomous logistics and supply-chain orchestration (agentic AI for end-to-end logistics optimization)\n",
      "\n",
      "Why this area is compelling\n",
      "- Data-rich, complex environment with real-time constraints (traffic, weather, inventory levels, demand spikes).\n",
      "- High potential ROI from faster delivery, lower transportation and warehousing costs, better asset utilization, and improved service levels.\n",
      "- Strong need for coordination across multiple systems and stakeholders (shippers, carriers, warehouses, suppliers, retailers).\n",
      "\n",
      "What an Agentic AI would do in this space\n",
      "- Dynamic routing and dispatch: autonomously plan and re-optimize routes and driver assignments in real time as conditions change.\n",
      "- Inventory and slotting optimization: decide where to place stock in warehouses and how to allocate replenishments to meet demand with minimal delay.\n",
      "- Carrier and supplier negotiation: autonomously select carriers, negotiate rates within policy constraints, and schedule pickups with demand signals.\n",
      "- Disruption management: detect disruptions (delay, capacity shortfalls) and automatically reconfigure plans, notify stakeholders, and trigger compensating actions.\n",
      "- End-to-end orchestration: coordinate across WMS, TMS, ERPs, and supplier portals to ensure actions are executable and auditable.\n",
      "\n",
      "Target customers and verticals\n",
      "- eCommerce and omnichannel retailers\n",
      "- 3PLs and freight forwarders\n",
      "- Retail distribution networks\n",
      "- Manufacturers with global supply chains\n",
      "- Last-mile delivery providers\n",
      "\n",
      "Value proposition\n",
      "- Reduce total landed cost per order\n",
      "- Improve on-time delivery and service levels\n",
      "- Increase asset utilization (vehicles, warehouse space, etc.)\n",
      "- Improve resilience to disruptions (weather, strikes, demand swings)\n",
      "\n",
      "Key data and tech requirements\n",
      "- Real-time telemetry: GPS, vehicle sensors, driver status\n",
      "- Warehouse data: WMS, slotting, inbound/outbound planning\n",
      "- Transportation management data: carrier rates, capacity, insure/claims\n",
      "- Demand signals: POS, forecasts, order streams\n",
      "- External feeds: traffic, weather, customs, regulatory constraints\n",
      "- Optimization and planning stack: multi-objective optimization, constraints handling, policy rules, risk controls\n",
      "- Security and governance: role-based access, audit trails, human-in-the-loop fallbacks\n",
      "\n",
      "High-level architecture\n",
      "- Agent layer: autonomous planners/negotiators with goals, constraints, and learning components\n",
      "- Orchestration layer: policy engine, workflow management, conflict resolution\n",
      "- Integration layer: connectors to WMS, TMS, ERP, carrier portals, IoT feeds\n",
      "- Execution/system layer: APIs and adapters to enact changes (route updates, PO changes, slotting moves)\n",
      "\n",
      "Risks and mitigations\n",
      "- Data quality and interoperability: invest in standardized data models and robust ETL; phased pilots with clear data quality gates.\n",
      "- Safety and compliance: enforce human overrides for critical decisions; implement guardrails and compliance checks (hours of service, safety regs).\n",
      "- Change management: start with non-disruptive pilots; measure savings and build from early wins.\n",
      "- Security: rigorous access controls, encryption, monitoring of agent actions.\n",
      "- Dependency on external partners: include service-level agreements and fallback modes.\n",
      "\n",
      "MVP outline (12–16 weeks)\n",
      "- Scope: dynamic routing for last-mile delivery and basic warehouse slotting optimization.\n",
      "- Data: integrate with a single TMS/WMS, live carrier feeds, and a small set of routes/orders.\n",
      "- Outcomes to prove: 10–20% reduction in transportation costs; improvement in on-time deliveries; faster disruption response.\n",
      "- Deliverables: a pilot dashboard, a decision engine for routing and slotting, a safe override workflow.\n",
      "\n",
      "Success metrics to track\n",
      "- Total landed cost per order\n",
      "- On-time delivery rate\n",
      "- Fleet utilization (miles per delivery, idle time)\n",
      "- Warehouse throughput and slotting efficiency\n",
      "- Plan stability and disruption recovery time\n",
      "- Adoption rate by operators (human-in-the-loop usage)\n",
      "\n",
      "If you’d like, I can also propose an alternative area (e.g., autonomous procurement/negotiation, or agentic AI for field service management) with a tailored MVP plan. Would you prefer another area or want to dive deeper into this one?\n"
     ]
    }
   ],
   "source": [
    "# First create the messages:\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"pick a business area that might be worth exploring for an Agentic AI opportunity\"}]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Then read the business idea:\n",
    "\n",
    "business_idea = response.choices[0].message.content\n",
    "print(business_idea)\n",
    "\n",
    "# And repeat! In the next message, include the business idea within the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pain-point: Real-time disruption management and cascading plan drift in multi-echelon logistics networks\n",
      "\n",
      "What the pain looks like\n",
      "- Disruptions (weather events, port congestion, vessel delays, supplier lead-time variability, strikes) ripple across the entire supply chain.\n",
      "- Operations teams must manually detect the disruption, re-sequence inbound and outbound flows, re-slot inventory in warehouses, reschedule production and labor, and re-negotiate carrier capacity—all while trying to keep commitments to retailers and customers.\n",
      "- Even when a disruption is identified, decisions must be made under uncertainty with multiple constraints (service levels, cost targets, factory/warehouse capacities, hours-of-service rules), and changes must be communicated to dozens of partners (carriers, suppliers, warehouses, retailers) in near real time.\n",
      "- The result: degraded on-time delivery, higher landed costs, wasted asset utilization, and erosion of customer trust due to late or inaccurate updates.\n",
      "\n",
      "Why this is particularly painful in current systems\n",
      "- Data silos and noisy signals: disruptions come from many sources (weather feeds, port status, transit visibility, supplier alerts) and are hard to fuse quickly into a single actionable view.\n",
      "- Slow, manual replanning: humans juggle dashboards, emails, and phone calls to adjust routes, PO receipts, dock appointments, and slotting—leading to delays and suboptimal choices.\n",
      "- Cascading effects: a single change (e.g., rerouting a truck) can force a dozen downstream adjustments (dock door schedules, inbound QC slots, labor loading plans, production calendars) that are hard to coordinate without an integrated control tower.\n",
      "- Lack of auditable, enforceable decisions: teams need an explainable record of why a particular replan was chosen, plus guardrails to prevent unsafe or non-compliant actions.\n",
      "\n",
      "How an Agentic AI approach would address it\n",
      "- Autonomous disruption detection: continuously ingests signals from transportation, warehouse, supplier, and external feeds to identify disruptions early.\n",
      "- End-to-end re-optimization: automatically re-plan routes, re-slot inventory, adjust inbound/outbound schedules, and realign production or procurement plans within policy constraints.\n",
      "- Carrier and supplier negotiation: proactively negotiates capacity, rates, and delivery windows with carriers and suppliers to restore service levels at target costs.\n",
      "- Stakeholder orchestration with governance: coordinates actions across WMS, TMS, ERPs, carrier portals, and supplier systems; provides auditable rationale and human override options when needed.\n",
      "- Rapid scenario testing: runs multiple what-if scenarios to compare disruption response options before committing to changes, reducing plan drift.\n",
      "\n",
      "Why this is ripe for Agentic AI\n",
      "- The problem spans data fusion, optimization under uncertainty, and multi-party negotiation—areas where autonomous agents can continuously learn, adapt, and act faster than human-only processes.\n",
      "- Operators benefit from a centralized, explainable control tower that can autonomously execute safe, auditable recovery actions while keeping humans in the loop for exception handling.\n",
      "- The value is clear: faster disruption recovery, restored service levels, lower incremental costs, and improved customer visibility.\n",
      "\n",
      "If you want, I can tailor this to a specific vertical (e.g., e-commerce last-mile, cross-border manufacturing, or 3PL networks) or outline a focused MVP to validate the disruption-management pain-point.\n"
     ]
    }
   ],
   "source": [
    "# Call 2: Pain point\n",
    "messages.append({\"role\": \"assistant\", \"content\": business_idea})\n",
    "messages.append({\"role\": \"user\", \"content\": \"present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.\"})\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "pain_point = response.choices[0].message.content\n",
    "print(pain_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed Agentic AI solution: Real-time disruption management and end-to-end plan recovery for multi-echelon logistics networks\n",
      "\n",
      "Problem recap\n",
      "- Disruptions ripple across transport, warehousing, production, and procurement, creating cascading plan drift.\n",
      "- Manual detection and replanning are slow, siloed, and often suboptimal, leading to late shipments, higher costs, and reduced customer trust.\n",
      "- An agentic system can continuously sense, decide, negotiate, and autonomously enact recoveries within guardrails, with human oversight as needed.\n",
      "\n",
      "What the solution does\n",
      "- Continuous disruption sensing\n",
      "  - Fuse signals from carriers, ports, weather, traffic, warehouse slots, inbound/outbound schedules, order streams, and supplier feeds.\n",
      "  - Detect disruptions early (anomalies in lead times, capacity, ETA variances) and assess their impact on service levels and cost.\n",
      "- End-to-end autonomous replanning\n",
      "  - Re-optimize multi-echelon plans: transportation routing, inbound/outbound schedules, dock/yard slots, inventory policies, and production/procurement calendars.\n",
      "  - Respect business rules, capacity constraints, hours-of-service, safety/compliance, and inventory service-level targets.\n",
      "- Proactive capacity negotiation\n",
      "  - Engage carriers and suppliers to secure capacity, adjust delivery windows, and negotiate rates within policy constraints.\n",
      "  - Propose alternative modes or routes when beneficial (e.g., alternative ports, expedited options with cost/risk trade-offs).\n",
      "- Orchestration with governance\n",
      "  - Centralized control tower that coordinates actions across WMS, TMS, ERP, carrier portals, and supplier systems.\n",
      "  - Provide explainable rationales for decisions, with auditable decision trails and human override points.\n",
      "- What-if scenario testing\n",
      "  - Run multiple contingency options in parallel to compare outcomes before committing to changes.\n",
      "- Stakeholder communication and traceability\n",
      "  - Automated, timely notifications to retailers, customers, warehouses, and carriers with ETA updates and rationale.\n",
      "\n",
      "Key capabilities aligned to pain-point\n",
      "- Real-time data fusion and anomaly detection\n",
      "- Multi-objective optimization under uncertainty\n",
      "- Autonomous negotiation within policy bounds\n",
      "- Safe human-in-the-loop governance and explainability\n",
      "- Seamless integration with existing planning and execution systems\n",
      "\n",
      "Target architecture (textual overview)\n",
      "- Data ingestion layer\n",
      "  - Ingests GPS/ETAs, carrier feeds, weather/traffic, WMS/TMS/ERP data, supplier signals, POS/forecast data.\n",
      "  - Data contracts and standardization to ensure interoperability across partners.\n",
      "- Agent layer (core agents)\n",
      "  - Disruption Detection Agent: flags disruptions and estimates impact.\n",
      "  - Replanning/Optimization Agent: generates end-to-end recovery plans (routes, slots, inventory, production, procurement).\n",
      "  - Negotiation Agent: proposes and negotiates capacity changes with carriers/suppliers within policy.\n",
      "  - Governance/Explainability Agent: records decisions, provides justifications, supports overrides.\n",
      "- Orchestration layer\n",
      "  - Policy engine and constraint manager: encodes business rules, SLAs, risk thresholds, and safety guardrails.\n",
      "  - Conflict resolution and plan-collision handling.\n",
      "- Execution layer\n",
      "  - Connectors to WMS, TMS, ERP, carrier portals, and supplier portals; issues changes (route updates, PO changes, slot reassignments) and retrieves status.\n",
      "  - Stakeholder-facing dashboards and alerting, with drill-down into rationale.\n",
      "- Learning & simulation layer (optional, long-term)\n",
      "  - Keeps a library of disruption scenarios, refines models via reinforcement learning or supervised feedback, and validates plans in sandbox mode.\n",
      "\n",
      "MVP plan and timeline\n",
      "Phase 1 (8–12 weeks): disruption sensing and triage\n",
      "- Build a data surface that ingests critical signals (carrier status, ETA variances, weather/port alerts, inbound/outbound SLAs, inventory levels).\n",
      "- Implement disruption detection and impact scoring.\n",
      "- Deliver a basic automated replanning loop for a single region/mode (e.g., domestic road transport with a couple of hubs) and a small set of carriers.\n",
      "- Provide a user-facing dashboard showing disruptions, recommended actions, and rationale.\n",
      "- Outcome: faster detection (minutes vs hours), first-pass automated recoveries, measurable improvements in service level and cost targets.\n",
      "\n",
      "Phase 2 (12–20 weeks): end-to-end orchestration and negotiation\n",
      "- Extend replanning to multi-echelon scope (air/sea/land transport, cross-docking, inbound/outbound, production scheduling, and inventory positioning).\n",
      "- Add negotiation capabilities with select key carriers and top suppliers; implement policy-compliant rate/capacity changes.\n",
      "- Implement what-if scenario testing for disruption containment and recovery options.\n",
      "- Strengthen governance: auditable decision trails, override workflow, compliance checks.\n",
      "- Outcome: robust end-to-end recovery with auditable decisions, improved resilience, and reduced manual replanning effort.\n",
      "\n",
      "Phase 3 (optional, 20+ weeks): scaling and learning\n",
      "- Federated rollout across geographies and more modes.\n",
      "- Advanced learning: refine anomaly thresholds, improve scenario accuracy, and optimize negotiation strategies through historical outcomes.\n",
      "- Deeper customer-visible exception handling and SLA adherence analytics.\n",
      "\n",
      "Quality and safety controls\n",
      "- Human-in-the-loop overrides for critical decisions (e.g., production stoppages, large cost penalties, safety-related changes).\n",
      "- Guardrails: protect hours-of-service compliance, safety/regulatory constraints, and customer contractual commitments.\n",
      "- Explainability: always provide a rationales trail for decisions; allow operators to trace how a replanning choice was derived.\n",
      "- Auditing and rollback: keep an immutable log of decisions; allow reversion to prior plans if needed.\n",
      "\n",
      "Data and integrations required\n",
      "- Real-time visibility data: GPS/telematics, dock status, WMS inbound/outbound, inventory levels, production orders.\n",
      "- Planning data: current TP/ERP data, forecast demand, supplier lead times, carrier capacity and rates, port/terminal status, weather/traffic feeds.\n",
      "- Standards and contracts: data models for messages between carriers, warehouses, and suppliers; clear data-sharing agreements and SLAs.\n",
      "- Security and governance: RBAC, encryption in transit at rest, secure APIs, and access auditing.\n",
      "\n",
      "Key success metrics\n",
      "- Time-to-detect disruption and time-to-recover\n",
      "- On-time delivery rate and service level adherence\n",
      "- Total landed cost and expediting cost reductions\n",
      "- Plan drift reduction (percentage deviation from baseline plan)\n",
      "- Carrier/supplier capacity utilization and favorable rate variance\n",
      "- Knock-on effects: dock/yard utilization, production schedule stability\n",
      "- Operator engagement: override rates, adoption, and feedback\n",
      "\n",
      "Risks and mitigations\n",
      "- Data quality and interoperability: implement data contracts, schema standardization, and phased pilots with quality gates.\n",
      "- Over-triggering and suboptimal changes: tune thresholding, require scenario validation, maintain human approvals for high-impact changes.\n",
      "- Vendor/partner dependency: design with fallback modes and partner SLAs; allow partial autonomy with safe-mode options.\n",
      "- Change management: start small, demonstrate wins, scale gradually; invest in training and clear communication.\n",
      "\n",
      "How this creates value\n",
      "- Faster, safer recovery from disruptions across the entire supply chain.\n",
      "- Reduced need for manual re-planning and firefighting; improved service levels and reliability.\n",
      "- Lower incremental costs from expedited shipments and overtime; better asset utilization.\n",
      "- Transparent, auditable decision processes that improve cross-team trust.\n",
      "\n",
      "Would you like me to tailor this to a specific industry vertical (e.g., e-commerce last-mile, cross-border manufacturing, or 3PL networks) or outline a concrete 2- to 3-page MVP spec with required data sources, integration points, and initial success criteria? I can also present a minimal technical blueprint (data models, agent roles, and interfaces) if that helps.\n"
     ]
    }
   ],
   "source": [
    "# Call 3: Agentic solution\n",
    "messages.append({\"role\": \"assistant\", \"content\": pain_point})\n",
    "messages.append({\"role\": \"user\", \"content\": \"propose an Agentic AI solution to address this pain point.\"})\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "agentic_solution = response.choices[0].message.content\n",
    "print(agentic_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
