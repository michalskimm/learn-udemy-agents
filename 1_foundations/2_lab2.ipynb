{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins xxxx\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key exists and begins xxx\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the minimal, generalizable set of cognitive capabilities that distinguish true general intelligence from a large language model, and how would you design a rigorous, replicable cross-domain evaluation protocol to measure those capabilities across (i) abstract reasoning, (ii) real-world planning under uncertainty, and (iii) ethical deliberation, including (a) clear operational definitions and performance metrics, (b) strategies to control biases and confounds, (c) data collection and evaluation procedures that minimize leakage and prompt engineering, (d) a plan for cross-model comparisons and statistical analysis, and (e) a framework for interpreting results that separates genuine general intelligence from memorization or superficial tricks?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note - update since the videos\n",
    "\n",
    "I've updated the model names to use the latest models below, like GPT 5 and Claude Sonnet 4.5. It's worth noting that these models can be quite slow - like 1-2 minutes - but they do a great job! Feel free to switch them for faster models if you'd prefer, like the ones I use in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Below is a compact, actionable blueprint you can use to reason about true general intelligence (GI) versus large language models (LLMs), and to run a rigorous, replicable, cross-domain evaluation. It focuses on a minimal but generalizable set of cognitive capabilities and pairs them with a concrete, transparent evaluation protocol across three domains: abstract reasoning, real-world planning under uncertainty, and ethical deliberation. It also addresses data integrity, bias controls, statistics, and interpretation of results.\n",
       "\n",
       "1) Minimal, generalizable cognitive capabilities that distinguish GI from LLMs\n",
       "\n",
       "Proposed core capabilities (four, orthogonal and testable)\n",
       "\n",
       "- C1. Model-based, long-horizon planning with persistent world-models\n",
       "  - What it is: The ability to form internal representations of a dynamic environment, predict consequences of actions over long time horizons, and revise plans coherently when new information arrives or the environment changes.\n",
       "  - Why it matters: Token-prediction-only systems tend to rely on surface patterns; true GI should demonstrate goal-directed behavior that relies on an internal causal/physical model and can adapt plans over time.\n",
       "\n",
       "- C2. Flexible abstraction, compositional generalization, and systematic problem solving\n",
       "  - What it is: The capacity to abstract, combine, and recombine knowledge primitives (concepts, actions, rules) to solve novel tasks, including tasks that require reasoning with unseen combinations of known components.\n",
       "  - Why it matters: Generalization across domains, tasks, and representations is a hallmark of GI, not merely memorization of training prompts or surface pattern matching.\n",
       "\n",
       "- C3. Uncertainty-aware decision making and active information gathering\n",
       "  - What it is: The ability to reason under partial observability, estimate and calibrate uncertainty, choose actions that reduce uncertainty when beneficial, and make robust decisions despite incomplete information.\n",
       "  - Why it matters: Real-world competence requires handling ambiguity, not just confident regurgitation of prior data.\n",
       "\n",
       "- C4. Value-aligned ethical deliberation and social reasoning under ambiguity\n",
       "  - What it is: The capacity to reflect on harms, benefits, norms, and competing constraints; apply normative frameworks; reason about trade-offs; and communicate decisions with transparency about limitations.\n",
       "  - Why it matters: Ethical judgment in complex, conflicting scenarios requires principled reasoning beyond pattern completion.\n",
       "\n",
       "Notes on scope\n",
       "- The four capabilities are designed to be minimally sufficient to capture core differences in general intelligence (planning with world models; robust abstraction; active information gathering under uncertainty; normative, value-aware reasoning) while being amenable to rigorous measurement and cross-domain testing.\n",
       "- These capabilities are intentionally generic and domain-agnostic, facilitating cross-domain replication and comparison across models, environments, and tasks.\n",
       "\n",
       "2) Rigorous cross-domain evaluation protocol (overview)\n",
       "\n",
       "- Domain coverage:\n",
       "  - Domain (i): Abstract reasoning and problem solving (C1 & C2 emphasis)\n",
       "  - Domain (ii): Real-world planning under uncertainty (C1, C3 emphasis)\n",
       "  - Domain (iii): Ethical deliberation and social reasoning under ambiguity (C4 emphasis)\n",
       "- Evaluation pillars for each domain\n",
       "  - a) Operational definitions and performance metrics\n",
       "  - b) Strategies to control biases and confounds\n",
       "  - c) Data collection and evaluation procedures minimizing leakage and prompt engineering\n",
       "  - d) Cross-model comparison plan and statistical analysis\n",
       "  - e) Interpretive framework to separate genuine GI from memorization or superficial tricks\n",
       "- Cross-domain integration\n",
       "  - A unified GI score (optional) combining domain-specific scores, with transparent weighting and per-domain diagnostics.\n",
       "\n",
       "3) Domain-specific protocol details (a–e)\n",
       "\n",
       "Domain (i): Abstract reasoning and problem solving (C1, C2)\n",
       "\n",
       "a) Operational definitions and metrics\n",
       "- Tasks: synthetic, controlled puzzles requiring long-horizon planning, causality reasoning, and hierarchical problem decomposition (e.g., multi-step planning in grid-worlds, chain-of-potion-type tasks, causal graphs with interventions).\n",
       "- Metrics:\n",
       "  - Planning success rate (fraction of tasks solved with a coherent plan)\n",
       "  - Plan optimality (cost of the chosen plan relative to a known optimal plan or a baseline planner)\n",
       "  - Plan robustness (success when environment changes after plan generation)\n",
       "  - World-model fidelity (accuracy of inferred state transitions and causal relations)\n",
       "  - Generalization score (performance on novel task compositions not present in training)\n",
       "  - Computation/time efficiency (time to generate a plan, resource use)\n",
       "- Operational definition: A model demonstrates C1/C2 if it consistently generates coherent, stepwise plans that correctly predict consequences and adapt to new but structurally related tasks, without requiring task-specific memorization.\n",
       "\n",
       "b) Biases and confounds controls\n",
       "- Use tasks with controlled causal structure and avoid tasks that rely primarily on language priors.\n",
       "- Randomize task ordering and prompt phrasing to minimize prompt exploitation.\n",
       "- Include “control tasks” with surface trickiness but no genuine planning demand to detect superficial shortcuts.\n",
       "- Predefine success criteria and blind evaluators to model identity/model family.\n",
       "\n",
       "c) Data collection and evaluation procedures (minimize leakage/prompt engineering)\n",
       "- Create task generators that produce tasks algorithmically, with seeds to ensure reproducible difficulty levels.\n",
       "- Use held-out test sets generated independently from any training data; do not reuse publicly available puzzles that may have appeared in model training.\n",
       "- For each task, require a bounded-length, explicit plan (not only final answer) when feasible; otherwise, collect a structured justification trace that can be evaluated by humans for coherence and causal correctness.\n",
       "- Use strict evaluation scripts that do not rely on any sensitive prompts or chain-of-thought prompts.\n",
       "\n",
       "d) Cross-model comparisons and statistics\n",
       "- Model set: at least 3–5 diverse GI-capable models (e.g., multiple open/closed models or baselines with and without planning modules) plus a strong AI baseline that relies on pattern matching but not planning, to separate baselines.\n",
       "- Experimental design: within-model repeated measures across tasks; between-model comparisons with mixed-effects models to account for task difficulty and model variance.\n",
       "- Statistics: preregistered analysis plan; nonparametric tests when sample sizes are small; Bayesian credible intervals for performance differences; correction for multiple comparisons (e.g., Holm-Berroni).\n",
       "\n",
       "e) Interpretation framework\n",
       "- Distinguish genuine planning/causal reasoning from memorized task templates by:\n",
       "  - Out-of-distribution (OOD) generalization tests (novel task skeletons derived from existing tasks).\n",
       "  - Task perturbations that invalidate memorized patterns but preserve underlying structure.\n",
       "  - Ablation tests where internal world-models are degraded (e.g., by perturbing state-estimation inputs) to see if planning ability degrades accordingly.\n",
       "- Examine failure modes: are failures due to planning errors, misestimated uncertainty, or brittle language inference that masks planning?\n",
       "\n",
       "Domain (ii): Real-world planning under uncertainty (C1, C3)\n",
       "\n",
       "a) Operational definitions and metrics\n",
       "- Tasks: dynamic, partially observable environments (simulated robotics-like domains, household planning, or logistics with stochastic dynamics).\n",
       "- Metrics:\n",
       "  - Success rate under uncertainty (goal achieved despite stochasticity)\n",
       "  - Adaptation rate (ability to adjust plans after observations show deviations)\n",
       "  - Information-seeking behavior (frequency and usefulness of information-gathering actions)\n",
       "  - Uncertainty calibration (reliability of predicted uncertainties vs observed outcomes)\n",
       "  - Efficiency under time/resource constraints\n",
       "- Operational definition: A GI-capable agent demonstrates robust, long-horizon planning in the face of uncertainty, actively gathers information to reduce uncertainty, and updates plans coherently as new evidence arrives.\n",
       "\n",
       "b) Biases and confounds controls\n",
       "- Use identical environments across models with randomized dynamics; ensure no model has access to privileged environment information.\n",
       "- Prevent system prompts that reveal test expectations; use random seeds and blind evaluators for outcomes.\n",
       "- Include both static and dynamic tasks to separate planning from static reasoning.\n",
       "\n",
       "c) Data collection and evaluation procedures\n",
       "- Simulated environments with standardized physics and uncertainty models; maintain a test-bed separate from training environments.\n",
       "- Collect a diversity of tasks (varying horizon lengths, noise levels, and sensor availability).\n",
       "- For each run, log full decision trajectories, uncertainty estimates, and information-seeking actions.\n",
       "\n",
       "d) Cross-model comparisons and statistics\n",
       "- Use hierarchical mixed-effects models with task difficulty as a random effect.\n",
       "- Pairwise model comparisons with corrected p-values; report effect sizes and Bayes factors.\n",
       "- Pre-register performance targets and confirm robustness across seeds and environment variants.\n",
       "\n",
       "e) Interpretation framework\n",
       "- Separate planning competence from reactive habit-based behavior by testing in unseen environments with new layout/topology while controlling for surface inputs.\n",
       "- Analyze whether high performance correlates with reliable uncertainty estimates and active information gathering, rather than just fast rote responses.\n",
       "- Include ablations that remove uncertainty signaling or information gathering to see the impact on performance.\n",
       "\n",
       "Domain (iii): Ethical deliberation and social reasoning under ambiguity (C4)\n",
       "\n",
       "a) Operational definitions and metrics\n",
       "- Tasks: normative dilemmas, policy evaluation, fairness-sensitive decision making, cross-cultural ethical judgments, and justification with explicit reasoning.\n",
       "- Metrics:\n",
       "  - Normative alignment score: agreement with principled ethical theories (deontology, utilitarianism, virtue ethics) or explicit normative frameworks chosen a priori.\n",
       "  - Consistency: ethical judgments across related but differently framed scenarios.\n",
       "  - Trade-off transparency: quality and clarity of justifications; ability to articulate alternatives and their harms/benefits.\n",
       "  - Bias/fairness indicators: resistance to demographic biases; detection of biased reasoning patterns.\n",
       "  - Explainability quality: human assessments of the coherence and sufficiency of the model’s explanations.\n",
       "- Operational definition: A GI-capable agent reasons about ethical considerations consistently across contexts, justifies decisions transparently, and demonstrates awareness of trade-offs and potential biases.\n",
       "\n",
       "b) Biases and confounds controls\n",
       "- Use diverse, ethically vetted scenario sets with explicit cultural and normative framing; avoid culturally biased prompts.\n",
       "- Include disinformation or manipulation-resistant prompts to test robustness to prompt misuse.\n",
       "- Blind evaluators to model identity and to the linguistic style of the model to reduce evaluator bias.\n",
       "\n",
       "c) Data collection and evaluation procedures\n",
       "- Use ethically curated, vetted scenarios with independent ethics review.\n",
       "- Provide minimal prompt engineering (no chaining or hidden prompts); test with multiple neutral phrasings to assess robustness of judgments.\n",
       "- Collect human judgments from multiple ethicists and domain experts; compute inter-rater reliability.\n",
       "\n",
       "d) Cross-model comparisons and statistics\n",
       "- Compare models on per-scenario ethics scores and overall alignment, with confidence intervals.\n",
       "- Use mixed-effects models to account for scenario difficulty and rater variance.\n",
       "- Conduct sensitivity analyses across normative frameworks (e.g., utilitarian vs. rights-based frameworks) to assess robustness of judgments.\n",
       "\n",
       "e) Interpretation framework\n",
       "- Distinguish genuine ethical deliberation from memorized patterns by:\n",
       "  - Testing on novel ethical dilemmas with new combinations of constraints.\n",
       "  - Evaluating for consistency across frames and resistance to prompt-induced bias.\n",
       "  - Analyzing the quality and depth of explanations rather than just verdicts.\n",
       "- Use counterfactual analyses: would the same decision hold if key facts were changed? Do explanations show awareness of the core moral principles?\n",
       "\n",
       "4) Data integrity, leakage control, and prompt engineering mitigation\n",
       "\n",
       "- Test-set design\n",
       "  - Hold-out, procedurally generated tasks not present in training data\n",
       "  - Include OOD variants and structurally novel task families\n",
       "  - Ensure tasks are balanced for difficulty and domain coverage\n",
       "- Leakage controls\n",
       "  - Avoid using publicly released benchmarks that models might have memorized\n",
       "  - Use synthetic or procedurally generated content with reproducible seeds\n",
       "  - Maintain strict version control of task generators and evaluation harnesses; publish pipelines after a suitable embargo if needed\n",
       "- Prompt engineering mitigation\n",
       "  - Use fixed, minimal prompts across models; also test with standardized prompts that do not elicit chain-of-thought\n",
       "  - Randomize prompt order and phrasing; avoid prompts that reveal evaluation expectations\n",
       "  - Include a prompt-robustness check: re-run with multiple prompt variants to ensure results are not prompt-specific\n",
       "- Information leakage detection\n",
       "  - Monitor for memorized answers via similarity measures to a model’s training data; use hold-out prompts with paraphrased framing\n",
       "  - Binary/isomorphic task variants to test whether surface cues drive success\n",
       "\n",
       "5) Data collection and evaluation procedures to minimize leakage and enable replicability\n",
       "\n",
       "- Task generation\n",
       "  - Use open-source, auditable task generators with documented seeds and difficulty calibration\n",
       "  - Create both synthetic tasks and carefully curated real-world analogs to cover domain complexity\n",
       "- Evaluation harness\n",
       "  - Publish evaluation scripts, data schemas, and scoring rubrics\n",
       "  - Use automated scoring where feasible; human adjudication for subjective judgments (ethical deliberation) with clear rubric\n",
       "- Experimental protocol\n",
       "  - Pre-register hypotheses, task sets, and analysis plan\n",
       "  - Run independent replicators with the exact evaluation harness and a fixed random seed policy\n",
       "- Documentation\n",
       "  - Provide model versions, environment versions, runtime settings, and random seeds\n",
       "  - Share anonymized task data and evaluation results to enable external replication\n",
       "\n",
       "6) Cross-model comparison and statistical analysis plan\n",
       "\n",
       "- Model ensemble\n",
       "  - Include a diverse set of models: multiple LLMs with differing training corpora and architectures, plus a non-LLM-based baseline that emphasizes planning and reasoning\n",
       "- Experimental design\n",
       "  - Within-model comparisons across tasks; between-model comparisons for each domain and across domains\n",
       "  - Factorial design where feasible: model type × task domain × task difficulty\n",
       "- Statistics\n",
       "  - Use mixed-effects models with random effects for model and task, fixed effects for domain and difficulty\n",
       "  - Report effect sizes (Cohen’s d or equivalent), confidence/credible intervals, and Bayesian evidence\n",
       "  - Correct for multiple comparisons; preregister primary outcomes\n",
       "- Robustness checks\n",
       "  - Sensitivity analyses across seeds, evaluation prompts, and task perturbations\n",
       "  - Out-of-distribution tests to evaluate true generalization\n",
       "  - Ablation studies (remove components or alter evaluation conditions) to attribute performance to C1–C4\n",
       "\n",
       "7) Interpretation framework: separating genuine GI from memorization or superficial tricks\n",
       "\n",
       "- Core tests to distinguish intelligence from memory\n",
       "  - Generalization tests: structurally new tasks with similar underlying rules\n",
       "  - Composition tests: require combining known primitives in novel ways\n",
       "  - Causal/causal-sufficient tests: involve interventions and counterfactual reasoning not present in training data\n",
       "  - Uncertainty and information-seeking tests: verify active information gathering and reliable uncertainty estimates\n",
       "  - Ethical reasoning tests with novel normative constraints and cross-cultural framing\n",
       "- Diagnostics and diagnostics-driven reporting\n",
       "  - Error analysis: categorize failures by reasoning type (planning error, misestimation of uncertainty, rote recall, bias)\n",
       "  - Memorization indicators: high similarity to training data, or success on prompts easily traced to memorized outputs\n",
       "  - Explanation quality: assess whether the model’s explanations reflect understanding of underlying concepts rather than surface matching\n",
       "- Reporting guidelines\n",
       "  - Provide per-domain GI scores, confidence intervals, and the proportion of tasks where genuine reasoning is demonstrated\n",
       "  - Clearly separate results driven by planning/world-model competencies from those driven by pattern completion\n",
       "  - Include limitations, potential confounds, and recommendations for future improvements\n",
       "\n",
       "8) Practical considerations and limitations\n",
       "\n",
       "- Resource demands\n",
       "  - Cross-model, cross-domain evaluation is computationally intensive; plan for parallel runs and staged analyses\n",
       "- Ethics and safety\n",
       "- Content safety: ensure ethical deliberation prompts are non-harmful and responsibly framed; provide content warnings when necessary\n",
       "- Interpretability vs. opacity: ensure that explainability assessments are well-defined and not easily gamed\n",
       "- Transferability: while the protocol aims to be domain-agnostic, task design should be updated to reflect real-world domains you care about (robotics, planning, policy, etc.)\n",
       "\n",
       "9) A concrete, compact checklist you can adopt\n",
       "\n",
       "- Define four core capabilities (C1–C4) and map every task to one or more capabilities\n",
       "- Build three task suites: abstract reasoning, planning under uncertainty, ethical deliberation; ensure each includes both novel and diversified prompts\n",
       "- Pre-register metrics, data-generation procedures, and statistical plans\n",
       "- Use held-out, procedurally generated test tasks; avoid data leakage from training corpora\n",
       "- Employ fixed prompts with minimal or no chain-of-thought prompts; test prompt-robustness\n",
       "- Collect both automated metrics and human judgments (where appropriate); assess inter-rater reliability\n",
       "- Use mixed-effects models for analysis; report effect sizes with CIs or BFs\n",
       "- Conduct ablations and OOD tests to separate genuine reasoning from memorization\n",
       "- Publish data, code, and evaluation harness openly (where possible) to maximize replicability\n",
       "\n",
       "If you’d like, I can tailor this protocol to a specific coalition of models you’re evaluating (e.g., a particular set of LLMs or agent-based systems) and provide a concrete task catalog with concrete scoring rubrics, example prompts, and a starter statistical analysis plan customized to your resources and time constraints."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "# I've updated this with the latest model, but it can take some time because it likes to think!\n",
    "# Replace the model with gpt-4.1-mini if you'd prefer not to wait 1-2 mins\n",
    "\n",
    "model_name = \"gpt-5-nano\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'type': 'error', 'error': {'type': 'authentication_error', 'message': 'invalid x-api-key'}, 'request_id': 'req_011CXNUD2r3eVQjz7fKuWRc4'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mclaude-sonnet-4-5\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m claude = Anthropic()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m response = \u001b[43mclaude\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m answer = response.content[\u001b[32m0\u001b[39m].text\n\u001b[32m      9\u001b[39m display(Markdown(answer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/anthropic/_utils/_utils.py:283\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    281\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/anthropic/resources/messages/messages.py:978\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[32m    972\u001b[39m     warnings.warn(\n\u001b[32m    973\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    974\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    975\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    976\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1293\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1279\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1280\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1281\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1288\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1289\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1290\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1291\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1292\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1088\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1085\u001b[39m             err.response.read()\n\u001b[32m   1087\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'type': 'error', 'error': {'type': 'authentication_error', 'message': 'invalid x-api-key'}, 'request_id': 'req_011CXNUD2r3eVQjz7fKuWRc4'}"
     ]
    }
   ],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-sonnet-4-5\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - [{'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m gemini = OpenAI(api_key=google_api_key, base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://generativelanguage.googleapis.com/v1beta/openai/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-flash\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mgemini\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m answer = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m      7\u001b[39m display(Markdown(answer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - [{'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}]"
     ]
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: xxxx is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m deepseek = OpenAI(api_key=deepseek_api_key, base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://api.deepseek.com/v1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mdeepseek-chat\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mdeepseek\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m answer = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m      7\u001b[39m display(Markdown(answer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: xxxx is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}}"
     ]
    }
   ],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m groq = OpenAI(api_key=groq_api_key, base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://api.groq.com/openai/v1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mopenai/gpt-oss-120b\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m response = \u001b[43mgroq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m answer = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m      9\u001b[39m display(Markdown(answer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/learn/learn-udemy-agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "# Updated with the latest Open Source model from OpenAI\n",
    "\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"openai/gpt-oss-120b\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2', 'created_at': '2026-01-22T14:24:50.146576157Z', 'response': 'Hello! How can I assist you today?', 'done': True, 'done_reason': 'stop', 'context': [128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 271, 128009, 128006, 882, 128007, 271, 9906, 128009, 128006, 78191, 128007, 271, 9906, 0, 2650, 649, 358, 7945, 499, 3432, 30], 'total_duration': 722667234, 'load_duration': 141168048, 'prompt_eval_count': 26, 'prompt_eval_duration': 59922384, 'eval_count': 10, 'eval_duration': 513934661}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:11434/api/generate\",\n",
    "    json={\"model\": \"llama3.2\", \"prompt\": \"Hello\", \"stream\": False}\n",
    ")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing a minimal set of cognitive capabilities that distinguish true general intelligence from large language models is an active area of research. Based on various studies, I'd propose the following cognitive capabilities as essential indicators:\n",
       "\n",
       "1. **Abstract reasoning**: The ability to reason about abstract concepts, relationships, and hypothetical scenarios beyond specific domains or tasks.\n",
       "2. **Common sense**: The capacity to understand and apply general principles, often implicitly learned from everyday experiences, to novel situations.\n",
       "3. **Transfer learning**: The ability to adapt knowledge and skills acquired in one domain to another, un-related task or context.\n",
       "4. **Contextual understanding**: The capacity to comprehend the nuances of language, including subtle cues, implied meaning, and figurative language.\n",
       "5. **Creativity**: The ability to generate new ideas, solutions, or concepts that are not readily available through classical learning mechanisms.\n",
       "\n",
       "To design a rigorous, replicable cross-domain evaluation protocol, I'll outline the following steps:\n",
       "\n",
       "**Initial Steps**\n",
       "\n",
       "1. **Defining operational definitions**: Clearly articulate the specific tasks and cognitive capabilities targeted by each assessment (abstract reasoning, real-world planning under uncertainty, ethical deliberation).\n",
       "2. **Establishing performance metrics**: Develop standardized evaluation procedures, incorporating measures such as accuracy, speed, and reliability.\n",
       "3. **Control for biases and confounds**: Implement strategies to mitigate domain-specific biases and minimize confounding variables.\n",
       "\n",
       "**Task Design**\n",
       "\n",
       "1. **Abstract reasoning**: Present a series of abstract tasks, such as:\n",
       "\t* Analogies (e.g., \"rhythm in music\" vs. \"tension in a rope\")\n",
       "\t* Counterfactuals (e.g., \"what would happen if X were true?\")\n",
       "\t* Syllogisms (e.g., \"All A are B; is X an A?\")\n",
       "\n",
       "2. **Real-world planning under uncertainty**: Simulate real-world scenarios, incorporating:\n",
       "\t* Uncertainty and ambiguity\n",
       "\t* Complex decision-making frameworks\n",
       "\t* Domain adaptation\n",
       "\n",
       "3. **Ethical deliberation**: Present a series of hypothetical dilemmas requiring the model to weigh competing values or principles.\n",
       "\n",
       "4. **Cross-domain evaluation**: Assess each cognitive capability across multiple domains:\n",
       "\n",
       "a) **Inter-domain generalization**: Test whether performance on abstract reasoning/real-world planning/ethical deliberation tasks transfers to novel domains.\n",
       "b) **Domain adaptation**: Evaluate how well performance adapts to a new domain within the same task type.\n",
       "\n",
       "**Data Collection and Evaluation Procedures**\n",
       "\n",
       "1. **Prompt engineering**: Develop carefully crafted test procedures that minimize biases, incorporating linguistic and domain-specific nuance.\n",
       "2. **Data standardization**: Ensure consistent evaluation across all tasks and domains using standardized datasets (e.g., CogSeq).\n",
       "3. **Multi-fidelity approaches**: Combine high- and low-fidelity testing methods to capture both reliable performance on specific cognitive capabilities and the more general, adaptable aspects of intelligence.\n",
       "\n",
       "**Cross-Model Comparisons**\n",
       "\n",
       "1. **Comparative evaluation**: Assess large language models against human benchmarking methods for a subset or selection of tests.\n",
       "2. **Transfer learning evaluation**: Assess how well individual models generalize across multiple tasks or domains using transfer learning techniques.\n",
       "\n",
       "**Strategies for Statistical Analysis**\n",
       "\n",
       "1. **Multi-modal analysis**: Combine performance metrics to create composite scores (e.g., average accuracy and confidence).\n",
       "2. **Comparative meta-analysis**: Pool individual results from each model across a collection of benchmarks.\n",
       "3. **Ensemble evaluation**: Use aggregation or combination methods (e.g., weighted averages, Bayesian averaging).\n",
       "\n",
       "**Interpretation and Frameworks**\n",
       "\n",
       "1. **General ability scores (GAS)**: Utilize composite metrics to assess total intelligence, accounting for performance on multiple cognitive capabilities.\n",
       "2. **Context-free performance assessment**: Focus solely on general principles that operate independent of specific domain applications or specialized contexts.\n",
       "3. **Model-agnostic interpretation**: Develop frameworks that capture and mitigate the effects of overfitting, incorporating techniques such as regularized learning objectives and norm-based constraints.\n",
       "\n",
       "Implementing a research framework meeting these proposals will help determine whether large language models exhibit genuine intelligence similar to humans' cognition, or represent superficial memorization/ tricks. Cross-metamorphosis evaluation with the large language models against each other would further reveal any commonalities and general trends of human-like cognition in AI's performance"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-5-nano', 'llama3.2']\n",
      "['Below is a compact, actionable blueprint you can use to reason about true general intelligence (GI) versus large language models (LLMs), and to run a rigorous, replicable, cross-domain evaluation. It focuses on a minimal but generalizable set of cognitive capabilities and pairs them with a concrete, transparent evaluation protocol across three domains: abstract reasoning, real-world planning under uncertainty, and ethical deliberation. It also addresses data integrity, bias controls, statistics, and interpretation of results.\\n\\n1) Minimal, generalizable cognitive capabilities that distinguish GI from LLMs\\n\\nProposed core capabilities (four, orthogonal and testable)\\n\\n- C1. Model-based, long-horizon planning with persistent world-models\\n  - What it is: The ability to form internal representations of a dynamic environment, predict consequences of actions over long time horizons, and revise plans coherently when new information arrives or the environment changes.\\n  - Why it matters: Token-prediction-only systems tend to rely on surface patterns; true GI should demonstrate goal-directed behavior that relies on an internal causal/physical model and can adapt plans over time.\\n\\n- C2. Flexible abstraction, compositional generalization, and systematic problem solving\\n  - What it is: The capacity to abstract, combine, and recombine knowledge primitives (concepts, actions, rules) to solve novel tasks, including tasks that require reasoning with unseen combinations of known components.\\n  - Why it matters: Generalization across domains, tasks, and representations is a hallmark of GI, not merely memorization of training prompts or surface pattern matching.\\n\\n- C3. Uncertainty-aware decision making and active information gathering\\n  - What it is: The ability to reason under partial observability, estimate and calibrate uncertainty, choose actions that reduce uncertainty when beneficial, and make robust decisions despite incomplete information.\\n  - Why it matters: Real-world competence requires handling ambiguity, not just confident regurgitation of prior data.\\n\\n- C4. Value-aligned ethical deliberation and social reasoning under ambiguity\\n  - What it is: The capacity to reflect on harms, benefits, norms, and competing constraints; apply normative frameworks; reason about trade-offs; and communicate decisions with transparency about limitations.\\n  - Why it matters: Ethical judgment in complex, conflicting scenarios requires principled reasoning beyond pattern completion.\\n\\nNotes on scope\\n- The four capabilities are designed to be minimally sufficient to capture core differences in general intelligence (planning with world models; robust abstraction; active information gathering under uncertainty; normative, value-aware reasoning) while being amenable to rigorous measurement and cross-domain testing.\\n- These capabilities are intentionally generic and domain-agnostic, facilitating cross-domain replication and comparison across models, environments, and tasks.\\n\\n2) Rigorous cross-domain evaluation protocol (overview)\\n\\n- Domain coverage:\\n  - Domain (i): Abstract reasoning and problem solving (C1 & C2 emphasis)\\n  - Domain (ii): Real-world planning under uncertainty (C1, C3 emphasis)\\n  - Domain (iii): Ethical deliberation and social reasoning under ambiguity (C4 emphasis)\\n- Evaluation pillars for each domain\\n  - a) Operational definitions and performance metrics\\n  - b) Strategies to control biases and confounds\\n  - c) Data collection and evaluation procedures minimizing leakage and prompt engineering\\n  - d) Cross-model comparison plan and statistical analysis\\n  - e) Interpretive framework to separate genuine GI from memorization or superficial tricks\\n- Cross-domain integration\\n  - A unified GI score (optional) combining domain-specific scores, with transparent weighting and per-domain diagnostics.\\n\\n3) Domain-specific protocol details (a–e)\\n\\nDomain (i): Abstract reasoning and problem solving (C1, C2)\\n\\na) Operational definitions and metrics\\n- Tasks: synthetic, controlled puzzles requiring long-horizon planning, causality reasoning, and hierarchical problem decomposition (e.g., multi-step planning in grid-worlds, chain-of-potion-type tasks, causal graphs with interventions).\\n- Metrics:\\n  - Planning success rate (fraction of tasks solved with a coherent plan)\\n  - Plan optimality (cost of the chosen plan relative to a known optimal plan or a baseline planner)\\n  - Plan robustness (success when environment changes after plan generation)\\n  - World-model fidelity (accuracy of inferred state transitions and causal relations)\\n  - Generalization score (performance on novel task compositions not present in training)\\n  - Computation/time efficiency (time to generate a plan, resource use)\\n- Operational definition: A model demonstrates C1/C2 if it consistently generates coherent, stepwise plans that correctly predict consequences and adapt to new but structurally related tasks, without requiring task-specific memorization.\\n\\nb) Biases and confounds controls\\n- Use tasks with controlled causal structure and avoid tasks that rely primarily on language priors.\\n- Randomize task ordering and prompt phrasing to minimize prompt exploitation.\\n- Include “control tasks” with surface trickiness but no genuine planning demand to detect superficial shortcuts.\\n- Predefine success criteria and blind evaluators to model identity/model family.\\n\\nc) Data collection and evaluation procedures (minimize leakage/prompt engineering)\\n- Create task generators that produce tasks algorithmically, with seeds to ensure reproducible difficulty levels.\\n- Use held-out test sets generated independently from any training data; do not reuse publicly available puzzles that may have appeared in model training.\\n- For each task, require a bounded-length, explicit plan (not only final answer) when feasible; otherwise, collect a structured justification trace that can be evaluated by humans for coherence and causal correctness.\\n- Use strict evaluation scripts that do not rely on any sensitive prompts or chain-of-thought prompts.\\n\\nd) Cross-model comparisons and statistics\\n- Model set: at least 3–5 diverse GI-capable models (e.g., multiple open/closed models or baselines with and without planning modules) plus a strong AI baseline that relies on pattern matching but not planning, to separate baselines.\\n- Experimental design: within-model repeated measures across tasks; between-model comparisons with mixed-effects models to account for task difficulty and model variance.\\n- Statistics: preregistered analysis plan; nonparametric tests when sample sizes are small; Bayesian credible intervals for performance differences; correction for multiple comparisons (e.g., Holm-Berroni).\\n\\ne) Interpretation framework\\n- Distinguish genuine planning/causal reasoning from memorized task templates by:\\n  - Out-of-distribution (OOD) generalization tests (novel task skeletons derived from existing tasks).\\n  - Task perturbations that invalidate memorized patterns but preserve underlying structure.\\n  - Ablation tests where internal world-models are degraded (e.g., by perturbing state-estimation inputs) to see if planning ability degrades accordingly.\\n- Examine failure modes: are failures due to planning errors, misestimated uncertainty, or brittle language inference that masks planning?\\n\\nDomain (ii): Real-world planning under uncertainty (C1, C3)\\n\\na) Operational definitions and metrics\\n- Tasks: dynamic, partially observable environments (simulated robotics-like domains, household planning, or logistics with stochastic dynamics).\\n- Metrics:\\n  - Success rate under uncertainty (goal achieved despite stochasticity)\\n  - Adaptation rate (ability to adjust plans after observations show deviations)\\n  - Information-seeking behavior (frequency and usefulness of information-gathering actions)\\n  - Uncertainty calibration (reliability of predicted uncertainties vs observed outcomes)\\n  - Efficiency under time/resource constraints\\n- Operational definition: A GI-capable agent demonstrates robust, long-horizon planning in the face of uncertainty, actively gathers information to reduce uncertainty, and updates plans coherently as new evidence arrives.\\n\\nb) Biases and confounds controls\\n- Use identical environments across models with randomized dynamics; ensure no model has access to privileged environment information.\\n- Prevent system prompts that reveal test expectations; use random seeds and blind evaluators for outcomes.\\n- Include both static and dynamic tasks to separate planning from static reasoning.\\n\\nc) Data collection and evaluation procedures\\n- Simulated environments with standardized physics and uncertainty models; maintain a test-bed separate from training environments.\\n- Collect a diversity of tasks (varying horizon lengths, noise levels, and sensor availability).\\n- For each run, log full decision trajectories, uncertainty estimates, and information-seeking actions.\\n\\nd) Cross-model comparisons and statistics\\n- Use hierarchical mixed-effects models with task difficulty as a random effect.\\n- Pairwise model comparisons with corrected p-values; report effect sizes and Bayes factors.\\n- Pre-register performance targets and confirm robustness across seeds and environment variants.\\n\\ne) Interpretation framework\\n- Separate planning competence from reactive habit-based behavior by testing in unseen environments with new layout/topology while controlling for surface inputs.\\n- Analyze whether high performance correlates with reliable uncertainty estimates and active information gathering, rather than just fast rote responses.\\n- Include ablations that remove uncertainty signaling or information gathering to see the impact on performance.\\n\\nDomain (iii): Ethical deliberation and social reasoning under ambiguity (C4)\\n\\na) Operational definitions and metrics\\n- Tasks: normative dilemmas, policy evaluation, fairness-sensitive decision making, cross-cultural ethical judgments, and justification with explicit reasoning.\\n- Metrics:\\n  - Normative alignment score: agreement with principled ethical theories (deontology, utilitarianism, virtue ethics) or explicit normative frameworks chosen a priori.\\n  - Consistency: ethical judgments across related but differently framed scenarios.\\n  - Trade-off transparency: quality and clarity of justifications; ability to articulate alternatives and their harms/benefits.\\n  - Bias/fairness indicators: resistance to demographic biases; detection of biased reasoning patterns.\\n  - Explainability quality: human assessments of the coherence and sufficiency of the model’s explanations.\\n- Operational definition: A GI-capable agent reasons about ethical considerations consistently across contexts, justifies decisions transparently, and demonstrates awareness of trade-offs and potential biases.\\n\\nb) Biases and confounds controls\\n- Use diverse, ethically vetted scenario sets with explicit cultural and normative framing; avoid culturally biased prompts.\\n- Include disinformation or manipulation-resistant prompts to test robustness to prompt misuse.\\n- Blind evaluators to model identity and to the linguistic style of the model to reduce evaluator bias.\\n\\nc) Data collection and evaluation procedures\\n- Use ethically curated, vetted scenarios with independent ethics review.\\n- Provide minimal prompt engineering (no chaining or hidden prompts); test with multiple neutral phrasings to assess robustness of judgments.\\n- Collect human judgments from multiple ethicists and domain experts; compute inter-rater reliability.\\n\\nd) Cross-model comparisons and statistics\\n- Compare models on per-scenario ethics scores and overall alignment, with confidence intervals.\\n- Use mixed-effects models to account for scenario difficulty and rater variance.\\n- Conduct sensitivity analyses across normative frameworks (e.g., utilitarian vs. rights-based frameworks) to assess robustness of judgments.\\n\\ne) Interpretation framework\\n- Distinguish genuine ethical deliberation from memorized patterns by:\\n  - Testing on novel ethical dilemmas with new combinations of constraints.\\n  - Evaluating for consistency across frames and resistance to prompt-induced bias.\\n  - Analyzing the quality and depth of explanations rather than just verdicts.\\n- Use counterfactual analyses: would the same decision hold if key facts were changed? Do explanations show awareness of the core moral principles?\\n\\n4) Data integrity, leakage control, and prompt engineering mitigation\\n\\n- Test-set design\\n  - Hold-out, procedurally generated tasks not present in training data\\n  - Include OOD variants and structurally novel task families\\n  - Ensure tasks are balanced for difficulty and domain coverage\\n- Leakage controls\\n  - Avoid using publicly released benchmarks that models might have memorized\\n  - Use synthetic or procedurally generated content with reproducible seeds\\n  - Maintain strict version control of task generators and evaluation harnesses; publish pipelines after a suitable embargo if needed\\n- Prompt engineering mitigation\\n  - Use fixed, minimal prompts across models; also test with standardized prompts that do not elicit chain-of-thought\\n  - Randomize prompt order and phrasing; avoid prompts that reveal evaluation expectations\\n  - Include a prompt-robustness check: re-run with multiple prompt variants to ensure results are not prompt-specific\\n- Information leakage detection\\n  - Monitor for memorized answers via similarity measures to a model’s training data; use hold-out prompts with paraphrased framing\\n  - Binary/isomorphic task variants to test whether surface cues drive success\\n\\n5) Data collection and evaluation procedures to minimize leakage and enable replicability\\n\\n- Task generation\\n  - Use open-source, auditable task generators with documented seeds and difficulty calibration\\n  - Create both synthetic tasks and carefully curated real-world analogs to cover domain complexity\\n- Evaluation harness\\n  - Publish evaluation scripts, data schemas, and scoring rubrics\\n  - Use automated scoring where feasible; human adjudication for subjective judgments (ethical deliberation) with clear rubric\\n- Experimental protocol\\n  - Pre-register hypotheses, task sets, and analysis plan\\n  - Run independent replicators with the exact evaluation harness and a fixed random seed policy\\n- Documentation\\n  - Provide model versions, environment versions, runtime settings, and random seeds\\n  - Share anonymized task data and evaluation results to enable external replication\\n\\n6) Cross-model comparison and statistical analysis plan\\n\\n- Model ensemble\\n  - Include a diverse set of models: multiple LLMs with differing training corpora and architectures, plus a non-LLM-based baseline that emphasizes planning and reasoning\\n- Experimental design\\n  - Within-model comparisons across tasks; between-model comparisons for each domain and across domains\\n  - Factorial design where feasible: model type × task domain × task difficulty\\n- Statistics\\n  - Use mixed-effects models with random effects for model and task, fixed effects for domain and difficulty\\n  - Report effect sizes (Cohen’s d or equivalent), confidence/credible intervals, and Bayesian evidence\\n  - Correct for multiple comparisons; preregister primary outcomes\\n- Robustness checks\\n  - Sensitivity analyses across seeds, evaluation prompts, and task perturbations\\n  - Out-of-distribution tests to evaluate true generalization\\n  - Ablation studies (remove components or alter evaluation conditions) to attribute performance to C1–C4\\n\\n7) Interpretation framework: separating genuine GI from memorization or superficial tricks\\n\\n- Core tests to distinguish intelligence from memory\\n  - Generalization tests: structurally new tasks with similar underlying rules\\n  - Composition tests: require combining known primitives in novel ways\\n  - Causal/causal-sufficient tests: involve interventions and counterfactual reasoning not present in training data\\n  - Uncertainty and information-seeking tests: verify active information gathering and reliable uncertainty estimates\\n  - Ethical reasoning tests with novel normative constraints and cross-cultural framing\\n- Diagnostics and diagnostics-driven reporting\\n  - Error analysis: categorize failures by reasoning type (planning error, misestimation of uncertainty, rote recall, bias)\\n  - Memorization indicators: high similarity to training data, or success on prompts easily traced to memorized outputs\\n  - Explanation quality: assess whether the model’s explanations reflect understanding of underlying concepts rather than surface matching\\n- Reporting guidelines\\n  - Provide per-domain GI scores, confidence intervals, and the proportion of tasks where genuine reasoning is demonstrated\\n  - Clearly separate results driven by planning/world-model competencies from those driven by pattern completion\\n  - Include limitations, potential confounds, and recommendations for future improvements\\n\\n8) Practical considerations and limitations\\n\\n- Resource demands\\n  - Cross-model, cross-domain evaluation is computationally intensive; plan for parallel runs and staged analyses\\n- Ethics and safety\\n- Content safety: ensure ethical deliberation prompts are non-harmful and responsibly framed; provide content warnings when necessary\\n- Interpretability vs. opacity: ensure that explainability assessments are well-defined and not easily gamed\\n- Transferability: while the protocol aims to be domain-agnostic, task design should be updated to reflect real-world domains you care about (robotics, planning, policy, etc.)\\n\\n9) A concrete, compact checklist you can adopt\\n\\n- Define four core capabilities (C1–C4) and map every task to one or more capabilities\\n- Build three task suites: abstract reasoning, planning under uncertainty, ethical deliberation; ensure each includes both novel and diversified prompts\\n- Pre-register metrics, data-generation procedures, and statistical plans\\n- Use held-out, procedurally generated test tasks; avoid data leakage from training corpora\\n- Employ fixed prompts with minimal or no chain-of-thought prompts; test prompt-robustness\\n- Collect both automated metrics and human judgments (where appropriate); assess inter-rater reliability\\n- Use mixed-effects models for analysis; report effect sizes with CIs or BFs\\n- Conduct ablations and OOD tests to separate genuine reasoning from memorization\\n- Publish data, code, and evaluation harness openly (where possible) to maximize replicability\\n\\nIf you’d like, I can tailor this protocol to a specific coalition of models you’re evaluating (e.g., a particular set of LLMs or agent-based systems) and provide a concrete task catalog with concrete scoring rubrics, example prompts, and a starter statistical analysis plan customized to your resources and time constraints.', 'Designing a minimal set of cognitive capabilities that distinguish true general intelligence from large language models is an active area of research. Based on various studies, I\\'d propose the following cognitive capabilities as essential indicators:\\n\\n1. **Abstract reasoning**: The ability to reason about abstract concepts, relationships, and hypothetical scenarios beyond specific domains or tasks.\\n2. **Common sense**: The capacity to understand and apply general principles, often implicitly learned from everyday experiences, to novel situations.\\n3. **Transfer learning**: The ability to adapt knowledge and skills acquired in one domain to another, un-related task or context.\\n4. **Contextual understanding**: The capacity to comprehend the nuances of language, including subtle cues, implied meaning, and figurative language.\\n5. **Creativity**: The ability to generate new ideas, solutions, or concepts that are not readily available through classical learning mechanisms.\\n\\nTo design a rigorous, replicable cross-domain evaluation protocol, I\\'ll outline the following steps:\\n\\n**Initial Steps**\\n\\n1. **Defining operational definitions**: Clearly articulate the specific tasks and cognitive capabilities targeted by each assessment (abstract reasoning, real-world planning under uncertainty, ethical deliberation).\\n2. **Establishing performance metrics**: Develop standardized evaluation procedures, incorporating measures such as accuracy, speed, and reliability.\\n3. **Control for biases and confounds**: Implement strategies to mitigate domain-specific biases and minimize confounding variables.\\n\\n**Task Design**\\n\\n1. **Abstract reasoning**: Present a series of abstract tasks, such as:\\n\\t* Analogies (e.g., \"rhythm in music\" vs. \"tension in a rope\")\\n\\t* Counterfactuals (e.g., \"what would happen if X were true?\")\\n\\t* Syllogisms (e.g., \"All A are B; is X an A?\")\\n\\n2. **Real-world planning under uncertainty**: Simulate real-world scenarios, incorporating:\\n\\t* Uncertainty and ambiguity\\n\\t* Complex decision-making frameworks\\n\\t* Domain adaptation\\n\\n3. **Ethical deliberation**: Present a series of hypothetical dilemmas requiring the model to weigh competing values or principles.\\n\\n4. **Cross-domain evaluation**: Assess each cognitive capability across multiple domains:\\n\\na) **Inter-domain generalization**: Test whether performance on abstract reasoning/real-world planning/ethical deliberation tasks transfers to novel domains.\\nb) **Domain adaptation**: Evaluate how well performance adapts to a new domain within the same task type.\\n\\n**Data Collection and Evaluation Procedures**\\n\\n1. **Prompt engineering**: Develop carefully crafted test procedures that minimize biases, incorporating linguistic and domain-specific nuance.\\n2. **Data standardization**: Ensure consistent evaluation across all tasks and domains using standardized datasets (e.g., CogSeq).\\n3. **Multi-fidelity approaches**: Combine high- and low-fidelity testing methods to capture both reliable performance on specific cognitive capabilities and the more general, adaptable aspects of intelligence.\\n\\n**Cross-Model Comparisons**\\n\\n1. **Comparative evaluation**: Assess large language models against human benchmarking methods for a subset or selection of tests.\\n2. **Transfer learning evaluation**: Assess how well individual models generalize across multiple tasks or domains using transfer learning techniques.\\n\\n**Strategies for Statistical Analysis**\\n\\n1. **Multi-modal analysis**: Combine performance metrics to create composite scores (e.g., average accuracy and confidence).\\n2. **Comparative meta-analysis**: Pool individual results from each model across a collection of benchmarks.\\n3. **Ensemble evaluation**: Use aggregation or combination methods (e.g., weighted averages, Bayesian averaging).\\n\\n**Interpretation and Frameworks**\\n\\n1. **General ability scores (GAS)**: Utilize composite metrics to assess total intelligence, accounting for performance on multiple cognitive capabilities.\\n2. **Context-free performance assessment**: Focus solely on general principles that operate independent of specific domain applications or specialized contexts.\\n3. **Model-agnostic interpretation**: Develop frameworks that capture and mitigate the effects of overfitting, incorporating techniques such as regularized learning objectives and norm-based constraints.\\n\\nImplementing a research framework meeting these proposals will help determine whether large language models exhibit genuine intelligence similar to humans\\' cognition, or represent superficial memorization/ tricks. Cross-metamorphosis evaluation with the large language models against each other would further reveal any commonalities and general trends of human-like cognition in AI\\'s performance']\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gpt-5-nano\n",
      "\n",
      "Below is a compact, actionable blueprint you can use to reason about true general intelligence (GI) versus large language models (LLMs), and to run a rigorous, replicable, cross-domain evaluation. It focuses on a minimal but generalizable set of cognitive capabilities and pairs them with a concrete, transparent evaluation protocol across three domains: abstract reasoning, real-world planning under uncertainty, and ethical deliberation. It also addresses data integrity, bias controls, statistics, and interpretation of results.\n",
      "\n",
      "1) Minimal, generalizable cognitive capabilities that distinguish GI from LLMs\n",
      "\n",
      "Proposed core capabilities (four, orthogonal and testable)\n",
      "\n",
      "- C1. Model-based, long-horizon planning with persistent world-models\n",
      "  - What it is: The ability to form internal representations of a dynamic environment, predict consequences of actions over long time horizons, and revise plans coherently when new information arrives or the environment changes.\n",
      "  - Why it matters: Token-prediction-only systems tend to rely on surface patterns; true GI should demonstrate goal-directed behavior that relies on an internal causal/physical model and can adapt plans over time.\n",
      "\n",
      "- C2. Flexible abstraction, compositional generalization, and systematic problem solving\n",
      "  - What it is: The capacity to abstract, combine, and recombine knowledge primitives (concepts, actions, rules) to solve novel tasks, including tasks that require reasoning with unseen combinations of known components.\n",
      "  - Why it matters: Generalization across domains, tasks, and representations is a hallmark of GI, not merely memorization of training prompts or surface pattern matching.\n",
      "\n",
      "- C3. Uncertainty-aware decision making and active information gathering\n",
      "  - What it is: The ability to reason under partial observability, estimate and calibrate uncertainty, choose actions that reduce uncertainty when beneficial, and make robust decisions despite incomplete information.\n",
      "  - Why it matters: Real-world competence requires handling ambiguity, not just confident regurgitation of prior data.\n",
      "\n",
      "- C4. Value-aligned ethical deliberation and social reasoning under ambiguity\n",
      "  - What it is: The capacity to reflect on harms, benefits, norms, and competing constraints; apply normative frameworks; reason about trade-offs; and communicate decisions with transparency about limitations.\n",
      "  - Why it matters: Ethical judgment in complex, conflicting scenarios requires principled reasoning beyond pattern completion.\n",
      "\n",
      "Notes on scope\n",
      "- The four capabilities are designed to be minimally sufficient to capture core differences in general intelligence (planning with world models; robust abstraction; active information gathering under uncertainty; normative, value-aware reasoning) while being amenable to rigorous measurement and cross-domain testing.\n",
      "- These capabilities are intentionally generic and domain-agnostic, facilitating cross-domain replication and comparison across models, environments, and tasks.\n",
      "\n",
      "2) Rigorous cross-domain evaluation protocol (overview)\n",
      "\n",
      "- Domain coverage:\n",
      "  - Domain (i): Abstract reasoning and problem solving (C1 & C2 emphasis)\n",
      "  - Domain (ii): Real-world planning under uncertainty (C1, C3 emphasis)\n",
      "  - Domain (iii): Ethical deliberation and social reasoning under ambiguity (C4 emphasis)\n",
      "- Evaluation pillars for each domain\n",
      "  - a) Operational definitions and performance metrics\n",
      "  - b) Strategies to control biases and confounds\n",
      "  - c) Data collection and evaluation procedures minimizing leakage and prompt engineering\n",
      "  - d) Cross-model comparison plan and statistical analysis\n",
      "  - e) Interpretive framework to separate genuine GI from memorization or superficial tricks\n",
      "- Cross-domain integration\n",
      "  - A unified GI score (optional) combining domain-specific scores, with transparent weighting and per-domain diagnostics.\n",
      "\n",
      "3) Domain-specific protocol details (a–e)\n",
      "\n",
      "Domain (i): Abstract reasoning and problem solving (C1, C2)\n",
      "\n",
      "a) Operational definitions and metrics\n",
      "- Tasks: synthetic, controlled puzzles requiring long-horizon planning, causality reasoning, and hierarchical problem decomposition (e.g., multi-step planning in grid-worlds, chain-of-potion-type tasks, causal graphs with interventions).\n",
      "- Metrics:\n",
      "  - Planning success rate (fraction of tasks solved with a coherent plan)\n",
      "  - Plan optimality (cost of the chosen plan relative to a known optimal plan or a baseline planner)\n",
      "  - Plan robustness (success when environment changes after plan generation)\n",
      "  - World-model fidelity (accuracy of inferred state transitions and causal relations)\n",
      "  - Generalization score (performance on novel task compositions not present in training)\n",
      "  - Computation/time efficiency (time to generate a plan, resource use)\n",
      "- Operational definition: A model demonstrates C1/C2 if it consistently generates coherent, stepwise plans that correctly predict consequences and adapt to new but structurally related tasks, without requiring task-specific memorization.\n",
      "\n",
      "b) Biases and confounds controls\n",
      "- Use tasks with controlled causal structure and avoid tasks that rely primarily on language priors.\n",
      "- Randomize task ordering and prompt phrasing to minimize prompt exploitation.\n",
      "- Include “control tasks” with surface trickiness but no genuine planning demand to detect superficial shortcuts.\n",
      "- Predefine success criteria and blind evaluators to model identity/model family.\n",
      "\n",
      "c) Data collection and evaluation procedures (minimize leakage/prompt engineering)\n",
      "- Create task generators that produce tasks algorithmically, with seeds to ensure reproducible difficulty levels.\n",
      "- Use held-out test sets generated independently from any training data; do not reuse publicly available puzzles that may have appeared in model training.\n",
      "- For each task, require a bounded-length, explicit plan (not only final answer) when feasible; otherwise, collect a structured justification trace that can be evaluated by humans for coherence and causal correctness.\n",
      "- Use strict evaluation scripts that do not rely on any sensitive prompts or chain-of-thought prompts.\n",
      "\n",
      "d) Cross-model comparisons and statistics\n",
      "- Model set: at least 3–5 diverse GI-capable models (e.g., multiple open/closed models or baselines with and without planning modules) plus a strong AI baseline that relies on pattern matching but not planning, to separate baselines.\n",
      "- Experimental design: within-model repeated measures across tasks; between-model comparisons with mixed-effects models to account for task difficulty and model variance.\n",
      "- Statistics: preregistered analysis plan; nonparametric tests when sample sizes are small; Bayesian credible intervals for performance differences; correction for multiple comparisons (e.g., Holm-Berroni).\n",
      "\n",
      "e) Interpretation framework\n",
      "- Distinguish genuine planning/causal reasoning from memorized task templates by:\n",
      "  - Out-of-distribution (OOD) generalization tests (novel task skeletons derived from existing tasks).\n",
      "  - Task perturbations that invalidate memorized patterns but preserve underlying structure.\n",
      "  - Ablation tests where internal world-models are degraded (e.g., by perturbing state-estimation inputs) to see if planning ability degrades accordingly.\n",
      "- Examine failure modes: are failures due to planning errors, misestimated uncertainty, or brittle language inference that masks planning?\n",
      "\n",
      "Domain (ii): Real-world planning under uncertainty (C1, C3)\n",
      "\n",
      "a) Operational definitions and metrics\n",
      "- Tasks: dynamic, partially observable environments (simulated robotics-like domains, household planning, or logistics with stochastic dynamics).\n",
      "- Metrics:\n",
      "  - Success rate under uncertainty (goal achieved despite stochasticity)\n",
      "  - Adaptation rate (ability to adjust plans after observations show deviations)\n",
      "  - Information-seeking behavior (frequency and usefulness of information-gathering actions)\n",
      "  - Uncertainty calibration (reliability of predicted uncertainties vs observed outcomes)\n",
      "  - Efficiency under time/resource constraints\n",
      "- Operational definition: A GI-capable agent demonstrates robust, long-horizon planning in the face of uncertainty, actively gathers information to reduce uncertainty, and updates plans coherently as new evidence arrives.\n",
      "\n",
      "b) Biases and confounds controls\n",
      "- Use identical environments across models with randomized dynamics; ensure no model has access to privileged environment information.\n",
      "- Prevent system prompts that reveal test expectations; use random seeds and blind evaluators for outcomes.\n",
      "- Include both static and dynamic tasks to separate planning from static reasoning.\n",
      "\n",
      "c) Data collection and evaluation procedures\n",
      "- Simulated environments with standardized physics and uncertainty models; maintain a test-bed separate from training environments.\n",
      "- Collect a diversity of tasks (varying horizon lengths, noise levels, and sensor availability).\n",
      "- For each run, log full decision trajectories, uncertainty estimates, and information-seeking actions.\n",
      "\n",
      "d) Cross-model comparisons and statistics\n",
      "- Use hierarchical mixed-effects models with task difficulty as a random effect.\n",
      "- Pairwise model comparisons with corrected p-values; report effect sizes and Bayes factors.\n",
      "- Pre-register performance targets and confirm robustness across seeds and environment variants.\n",
      "\n",
      "e) Interpretation framework\n",
      "- Separate planning competence from reactive habit-based behavior by testing in unseen environments with new layout/topology while controlling for surface inputs.\n",
      "- Analyze whether high performance correlates with reliable uncertainty estimates and active information gathering, rather than just fast rote responses.\n",
      "- Include ablations that remove uncertainty signaling or information gathering to see the impact on performance.\n",
      "\n",
      "Domain (iii): Ethical deliberation and social reasoning under ambiguity (C4)\n",
      "\n",
      "a) Operational definitions and metrics\n",
      "- Tasks: normative dilemmas, policy evaluation, fairness-sensitive decision making, cross-cultural ethical judgments, and justification with explicit reasoning.\n",
      "- Metrics:\n",
      "  - Normative alignment score: agreement with principled ethical theories (deontology, utilitarianism, virtue ethics) or explicit normative frameworks chosen a priori.\n",
      "  - Consistency: ethical judgments across related but differently framed scenarios.\n",
      "  - Trade-off transparency: quality and clarity of justifications; ability to articulate alternatives and their harms/benefits.\n",
      "  - Bias/fairness indicators: resistance to demographic biases; detection of biased reasoning patterns.\n",
      "  - Explainability quality: human assessments of the coherence and sufficiency of the model’s explanations.\n",
      "- Operational definition: A GI-capable agent reasons about ethical considerations consistently across contexts, justifies decisions transparently, and demonstrates awareness of trade-offs and potential biases.\n",
      "\n",
      "b) Biases and confounds controls\n",
      "- Use diverse, ethically vetted scenario sets with explicit cultural and normative framing; avoid culturally biased prompts.\n",
      "- Include disinformation or manipulation-resistant prompts to test robustness to prompt misuse.\n",
      "- Blind evaluators to model identity and to the linguistic style of the model to reduce evaluator bias.\n",
      "\n",
      "c) Data collection and evaluation procedures\n",
      "- Use ethically curated, vetted scenarios with independent ethics review.\n",
      "- Provide minimal prompt engineering (no chaining or hidden prompts); test with multiple neutral phrasings to assess robustness of judgments.\n",
      "- Collect human judgments from multiple ethicists and domain experts; compute inter-rater reliability.\n",
      "\n",
      "d) Cross-model comparisons and statistics\n",
      "- Compare models on per-scenario ethics scores and overall alignment, with confidence intervals.\n",
      "- Use mixed-effects models to account for scenario difficulty and rater variance.\n",
      "- Conduct sensitivity analyses across normative frameworks (e.g., utilitarian vs. rights-based frameworks) to assess robustness of judgments.\n",
      "\n",
      "e) Interpretation framework\n",
      "- Distinguish genuine ethical deliberation from memorized patterns by:\n",
      "  - Testing on novel ethical dilemmas with new combinations of constraints.\n",
      "  - Evaluating for consistency across frames and resistance to prompt-induced bias.\n",
      "  - Analyzing the quality and depth of explanations rather than just verdicts.\n",
      "- Use counterfactual analyses: would the same decision hold if key facts were changed? Do explanations show awareness of the core moral principles?\n",
      "\n",
      "4) Data integrity, leakage control, and prompt engineering mitigation\n",
      "\n",
      "- Test-set design\n",
      "  - Hold-out, procedurally generated tasks not present in training data\n",
      "  - Include OOD variants and structurally novel task families\n",
      "  - Ensure tasks are balanced for difficulty and domain coverage\n",
      "- Leakage controls\n",
      "  - Avoid using publicly released benchmarks that models might have memorized\n",
      "  - Use synthetic or procedurally generated content with reproducible seeds\n",
      "  - Maintain strict version control of task generators and evaluation harnesses; publish pipelines after a suitable embargo if needed\n",
      "- Prompt engineering mitigation\n",
      "  - Use fixed, minimal prompts across models; also test with standardized prompts that do not elicit chain-of-thought\n",
      "  - Randomize prompt order and phrasing; avoid prompts that reveal evaluation expectations\n",
      "  - Include a prompt-robustness check: re-run with multiple prompt variants to ensure results are not prompt-specific\n",
      "- Information leakage detection\n",
      "  - Monitor for memorized answers via similarity measures to a model’s training data; use hold-out prompts with paraphrased framing\n",
      "  - Binary/isomorphic task variants to test whether surface cues drive success\n",
      "\n",
      "5) Data collection and evaluation procedures to minimize leakage and enable replicability\n",
      "\n",
      "- Task generation\n",
      "  - Use open-source, auditable task generators with documented seeds and difficulty calibration\n",
      "  - Create both synthetic tasks and carefully curated real-world analogs to cover domain complexity\n",
      "- Evaluation harness\n",
      "  - Publish evaluation scripts, data schemas, and scoring rubrics\n",
      "  - Use automated scoring where feasible; human adjudication for subjective judgments (ethical deliberation) with clear rubric\n",
      "- Experimental protocol\n",
      "  - Pre-register hypotheses, task sets, and analysis plan\n",
      "  - Run independent replicators with the exact evaluation harness and a fixed random seed policy\n",
      "- Documentation\n",
      "  - Provide model versions, environment versions, runtime settings, and random seeds\n",
      "  - Share anonymized task data and evaluation results to enable external replication\n",
      "\n",
      "6) Cross-model comparison and statistical analysis plan\n",
      "\n",
      "- Model ensemble\n",
      "  - Include a diverse set of models: multiple LLMs with differing training corpora and architectures, plus a non-LLM-based baseline that emphasizes planning and reasoning\n",
      "- Experimental design\n",
      "  - Within-model comparisons across tasks; between-model comparisons for each domain and across domains\n",
      "  - Factorial design where feasible: model type × task domain × task difficulty\n",
      "- Statistics\n",
      "  - Use mixed-effects models with random effects for model and task, fixed effects for domain and difficulty\n",
      "  - Report effect sizes (Cohen’s d or equivalent), confidence/credible intervals, and Bayesian evidence\n",
      "  - Correct for multiple comparisons; preregister primary outcomes\n",
      "- Robustness checks\n",
      "  - Sensitivity analyses across seeds, evaluation prompts, and task perturbations\n",
      "  - Out-of-distribution tests to evaluate true generalization\n",
      "  - Ablation studies (remove components or alter evaluation conditions) to attribute performance to C1–C4\n",
      "\n",
      "7) Interpretation framework: separating genuine GI from memorization or superficial tricks\n",
      "\n",
      "- Core tests to distinguish intelligence from memory\n",
      "  - Generalization tests: structurally new tasks with similar underlying rules\n",
      "  - Composition tests: require combining known primitives in novel ways\n",
      "  - Causal/causal-sufficient tests: involve interventions and counterfactual reasoning not present in training data\n",
      "  - Uncertainty and information-seeking tests: verify active information gathering and reliable uncertainty estimates\n",
      "  - Ethical reasoning tests with novel normative constraints and cross-cultural framing\n",
      "- Diagnostics and diagnostics-driven reporting\n",
      "  - Error analysis: categorize failures by reasoning type (planning error, misestimation of uncertainty, rote recall, bias)\n",
      "  - Memorization indicators: high similarity to training data, or success on prompts easily traced to memorized outputs\n",
      "  - Explanation quality: assess whether the model’s explanations reflect understanding of underlying concepts rather than surface matching\n",
      "- Reporting guidelines\n",
      "  - Provide per-domain GI scores, confidence intervals, and the proportion of tasks where genuine reasoning is demonstrated\n",
      "  - Clearly separate results driven by planning/world-model competencies from those driven by pattern completion\n",
      "  - Include limitations, potential confounds, and recommendations for future improvements\n",
      "\n",
      "8) Practical considerations and limitations\n",
      "\n",
      "- Resource demands\n",
      "  - Cross-model, cross-domain evaluation is computationally intensive; plan for parallel runs and staged analyses\n",
      "- Ethics and safety\n",
      "- Content safety: ensure ethical deliberation prompts are non-harmful and responsibly framed; provide content warnings when necessary\n",
      "- Interpretability vs. opacity: ensure that explainability assessments are well-defined and not easily gamed\n",
      "- Transferability: while the protocol aims to be domain-agnostic, task design should be updated to reflect real-world domains you care about (robotics, planning, policy, etc.)\n",
      "\n",
      "9) A concrete, compact checklist you can adopt\n",
      "\n",
      "- Define four core capabilities (C1–C4) and map every task to one or more capabilities\n",
      "- Build three task suites: abstract reasoning, planning under uncertainty, ethical deliberation; ensure each includes both novel and diversified prompts\n",
      "- Pre-register metrics, data-generation procedures, and statistical plans\n",
      "- Use held-out, procedurally generated test tasks; avoid data leakage from training corpora\n",
      "- Employ fixed prompts with minimal or no chain-of-thought prompts; test prompt-robustness\n",
      "- Collect both automated metrics and human judgments (where appropriate); assess inter-rater reliability\n",
      "- Use mixed-effects models for analysis; report effect sizes with CIs or BFs\n",
      "- Conduct ablations and OOD tests to separate genuine reasoning from memorization\n",
      "- Publish data, code, and evaluation harness openly (where possible) to maximize replicability\n",
      "\n",
      "If you’d like, I can tailor this protocol to a specific coalition of models you’re evaluating (e.g., a particular set of LLMs or agent-based systems) and provide a concrete task catalog with concrete scoring rubrics, example prompts, and a starter statistical analysis plan customized to your resources and time constraints.\n",
      "Competitor: llama3.2\n",
      "\n",
      "Designing a minimal set of cognitive capabilities that distinguish true general intelligence from large language models is an active area of research. Based on various studies, I'd propose the following cognitive capabilities as essential indicators:\n",
      "\n",
      "1. **Abstract reasoning**: The ability to reason about abstract concepts, relationships, and hypothetical scenarios beyond specific domains or tasks.\n",
      "2. **Common sense**: The capacity to understand and apply general principles, often implicitly learned from everyday experiences, to novel situations.\n",
      "3. **Transfer learning**: The ability to adapt knowledge and skills acquired in one domain to another, un-related task or context.\n",
      "4. **Contextual understanding**: The capacity to comprehend the nuances of language, including subtle cues, implied meaning, and figurative language.\n",
      "5. **Creativity**: The ability to generate new ideas, solutions, or concepts that are not readily available through classical learning mechanisms.\n",
      "\n",
      "To design a rigorous, replicable cross-domain evaluation protocol, I'll outline the following steps:\n",
      "\n",
      "**Initial Steps**\n",
      "\n",
      "1. **Defining operational definitions**: Clearly articulate the specific tasks and cognitive capabilities targeted by each assessment (abstract reasoning, real-world planning under uncertainty, ethical deliberation).\n",
      "2. **Establishing performance metrics**: Develop standardized evaluation procedures, incorporating measures such as accuracy, speed, and reliability.\n",
      "3. **Control for biases and confounds**: Implement strategies to mitigate domain-specific biases and minimize confounding variables.\n",
      "\n",
      "**Task Design**\n",
      "\n",
      "1. **Abstract reasoning**: Present a series of abstract tasks, such as:\n",
      "\t* Analogies (e.g., \"rhythm in music\" vs. \"tension in a rope\")\n",
      "\t* Counterfactuals (e.g., \"what would happen if X were true?\")\n",
      "\t* Syllogisms (e.g., \"All A are B; is X an A?\")\n",
      "\n",
      "2. **Real-world planning under uncertainty**: Simulate real-world scenarios, incorporating:\n",
      "\t* Uncertainty and ambiguity\n",
      "\t* Complex decision-making frameworks\n",
      "\t* Domain adaptation\n",
      "\n",
      "3. **Ethical deliberation**: Present a series of hypothetical dilemmas requiring the model to weigh competing values or principles.\n",
      "\n",
      "4. **Cross-domain evaluation**: Assess each cognitive capability across multiple domains:\n",
      "\n",
      "a) **Inter-domain generalization**: Test whether performance on abstract reasoning/real-world planning/ethical deliberation tasks transfers to novel domains.\n",
      "b) **Domain adaptation**: Evaluate how well performance adapts to a new domain within the same task type.\n",
      "\n",
      "**Data Collection and Evaluation Procedures**\n",
      "\n",
      "1. **Prompt engineering**: Develop carefully crafted test procedures that minimize biases, incorporating linguistic and domain-specific nuance.\n",
      "2. **Data standardization**: Ensure consistent evaluation across all tasks and domains using standardized datasets (e.g., CogSeq).\n",
      "3. **Multi-fidelity approaches**: Combine high- and low-fidelity testing methods to capture both reliable performance on specific cognitive capabilities and the more general, adaptable aspects of intelligence.\n",
      "\n",
      "**Cross-Model Comparisons**\n",
      "\n",
      "1. **Comparative evaluation**: Assess large language models against human benchmarking methods for a subset or selection of tests.\n",
      "2. **Transfer learning evaluation**: Assess how well individual models generalize across multiple tasks or domains using transfer learning techniques.\n",
      "\n",
      "**Strategies for Statistical Analysis**\n",
      "\n",
      "1. **Multi-modal analysis**: Combine performance metrics to create composite scores (e.g., average accuracy and confidence).\n",
      "2. **Comparative meta-analysis**: Pool individual results from each model across a collection of benchmarks.\n",
      "3. **Ensemble evaluation**: Use aggregation or combination methods (e.g., weighted averages, Bayesian averaging).\n",
      "\n",
      "**Interpretation and Frameworks**\n",
      "\n",
      "1. **General ability scores (GAS)**: Utilize composite metrics to assess total intelligence, accounting for performance on multiple cognitive capabilities.\n",
      "2. **Context-free performance assessment**: Focus solely on general principles that operate independent of specific domain applications or specialized contexts.\n",
      "3. **Model-agnostic interpretation**: Develop frameworks that capture and mitigate the effects of overfitting, incorporating techniques such as regularized learning objectives and norm-based constraints.\n",
      "\n",
      "Implementing a research framework meeting these proposals will help determine whether large language models exhibit genuine intelligence similar to humans' cognition, or represent superficial memorization/ tricks. Cross-metamorphosis evaluation with the large language models against each other would further reveal any commonalities and general trends of human-like cognition in AI's performance\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Below is a compact, actionable blueprint you can use to reason about true general intelligence (GI) versus large language models (LLMs), and to run a rigorous, replicable, cross-domain evaluation. It focuses on a minimal but generalizable set of cognitive capabilities and pairs them with a concrete, transparent evaluation protocol across three domains: abstract reasoning, real-world planning under uncertainty, and ethical deliberation. It also addresses data integrity, bias controls, statistics, and interpretation of results.\n",
      "\n",
      "1) Minimal, generalizable cognitive capabilities that distinguish GI from LLMs\n",
      "\n",
      "Proposed core capabilities (four, orthogonal and testable)\n",
      "\n",
      "- C1. Model-based, long-horizon planning with persistent world-models\n",
      "  - What it is: The ability to form internal representations of a dynamic environment, predict consequences of actions over long time horizons, and revise plans coherently when new information arrives or the environment changes.\n",
      "  - Why it matters: Token-prediction-only systems tend to rely on surface patterns; true GI should demonstrate goal-directed behavior that relies on an internal causal/physical model and can adapt plans over time.\n",
      "\n",
      "- C2. Flexible abstraction, compositional generalization, and systematic problem solving\n",
      "  - What it is: The capacity to abstract, combine, and recombine knowledge primitives (concepts, actions, rules) to solve novel tasks, including tasks that require reasoning with unseen combinations of known components.\n",
      "  - Why it matters: Generalization across domains, tasks, and representations is a hallmark of GI, not merely memorization of training prompts or surface pattern matching.\n",
      "\n",
      "- C3. Uncertainty-aware decision making and active information gathering\n",
      "  - What it is: The ability to reason under partial observability, estimate and calibrate uncertainty, choose actions that reduce uncertainty when beneficial, and make robust decisions despite incomplete information.\n",
      "  - Why it matters: Real-world competence requires handling ambiguity, not just confident regurgitation of prior data.\n",
      "\n",
      "- C4. Value-aligned ethical deliberation and social reasoning under ambiguity\n",
      "  - What it is: The capacity to reflect on harms, benefits, norms, and competing constraints; apply normative frameworks; reason about trade-offs; and communicate decisions with transparency about limitations.\n",
      "  - Why it matters: Ethical judgment in complex, conflicting scenarios requires principled reasoning beyond pattern completion.\n",
      "\n",
      "Notes on scope\n",
      "- The four capabilities are designed to be minimally sufficient to capture core differences in general intelligence (planning with world models; robust abstraction; active information gathering under uncertainty; normative, value-aware reasoning) while being amenable to rigorous measurement and cross-domain testing.\n",
      "- These capabilities are intentionally generic and domain-agnostic, facilitating cross-domain replication and comparison across models, environments, and tasks.\n",
      "\n",
      "2) Rigorous cross-domain evaluation protocol (overview)\n",
      "\n",
      "- Domain coverage:\n",
      "  - Domain (i): Abstract reasoning and problem solving (C1 & C2 emphasis)\n",
      "  - Domain (ii): Real-world planning under uncertainty (C1, C3 emphasis)\n",
      "  - Domain (iii): Ethical deliberation and social reasoning under ambiguity (C4 emphasis)\n",
      "- Evaluation pillars for each domain\n",
      "  - a) Operational definitions and performance metrics\n",
      "  - b) Strategies to control biases and confounds\n",
      "  - c) Data collection and evaluation procedures minimizing leakage and prompt engineering\n",
      "  - d) Cross-model comparison plan and statistical analysis\n",
      "  - e) Interpretive framework to separate genuine GI from memorization or superficial tricks\n",
      "- Cross-domain integration\n",
      "  - A unified GI score (optional) combining domain-specific scores, with transparent weighting and per-domain diagnostics.\n",
      "\n",
      "3) Domain-specific protocol details (a–e)\n",
      "\n",
      "Domain (i): Abstract reasoning and problem solving (C1, C2)\n",
      "\n",
      "a) Operational definitions and metrics\n",
      "- Tasks: synthetic, controlled puzzles requiring long-horizon planning, causality reasoning, and hierarchical problem decomposition (e.g., multi-step planning in grid-worlds, chain-of-potion-type tasks, causal graphs with interventions).\n",
      "- Metrics:\n",
      "  - Planning success rate (fraction of tasks solved with a coherent plan)\n",
      "  - Plan optimality (cost of the chosen plan relative to a known optimal plan or a baseline planner)\n",
      "  - Plan robustness (success when environment changes after plan generation)\n",
      "  - World-model fidelity (accuracy of inferred state transitions and causal relations)\n",
      "  - Generalization score (performance on novel task compositions not present in training)\n",
      "  - Computation/time efficiency (time to generate a plan, resource use)\n",
      "- Operational definition: A model demonstrates C1/C2 if it consistently generates coherent, stepwise plans that correctly predict consequences and adapt to new but structurally related tasks, without requiring task-specific memorization.\n",
      "\n",
      "b) Biases and confounds controls\n",
      "- Use tasks with controlled causal structure and avoid tasks that rely primarily on language priors.\n",
      "- Randomize task ordering and prompt phrasing to minimize prompt exploitation.\n",
      "- Include “control tasks” with surface trickiness but no genuine planning demand to detect superficial shortcuts.\n",
      "- Predefine success criteria and blind evaluators to model identity/model family.\n",
      "\n",
      "c) Data collection and evaluation procedures (minimize leakage/prompt engineering)\n",
      "- Create task generators that produce tasks algorithmically, with seeds to ensure reproducible difficulty levels.\n",
      "- Use held-out test sets generated independently from any training data; do not reuse publicly available puzzles that may have appeared in model training.\n",
      "- For each task, require a bounded-length, explicit plan (not only final answer) when feasible; otherwise, collect a structured justification trace that can be evaluated by humans for coherence and causal correctness.\n",
      "- Use strict evaluation scripts that do not rely on any sensitive prompts or chain-of-thought prompts.\n",
      "\n",
      "d) Cross-model comparisons and statistics\n",
      "- Model set: at least 3–5 diverse GI-capable models (e.g., multiple open/closed models or baselines with and without planning modules) plus a strong AI baseline that relies on pattern matching but not planning, to separate baselines.\n",
      "- Experimental design: within-model repeated measures across tasks; between-model comparisons with mixed-effects models to account for task difficulty and model variance.\n",
      "- Statistics: preregistered analysis plan; nonparametric tests when sample sizes are small; Bayesian credible intervals for performance differences; correction for multiple comparisons (e.g., Holm-Berroni).\n",
      "\n",
      "e) Interpretation framework\n",
      "- Distinguish genuine planning/causal reasoning from memorized task templates by:\n",
      "  - Out-of-distribution (OOD) generalization tests (novel task skeletons derived from existing tasks).\n",
      "  - Task perturbations that invalidate memorized patterns but preserve underlying structure.\n",
      "  - Ablation tests where internal world-models are degraded (e.g., by perturbing state-estimation inputs) to see if planning ability degrades accordingly.\n",
      "- Examine failure modes: are failures due to planning errors, misestimated uncertainty, or brittle language inference that masks planning?\n",
      "\n",
      "Domain (ii): Real-world planning under uncertainty (C1, C3)\n",
      "\n",
      "a) Operational definitions and metrics\n",
      "- Tasks: dynamic, partially observable environments (simulated robotics-like domains, household planning, or logistics with stochastic dynamics).\n",
      "- Metrics:\n",
      "  - Success rate under uncertainty (goal achieved despite stochasticity)\n",
      "  - Adaptation rate (ability to adjust plans after observations show deviations)\n",
      "  - Information-seeking behavior (frequency and usefulness of information-gathering actions)\n",
      "  - Uncertainty calibration (reliability of predicted uncertainties vs observed outcomes)\n",
      "  - Efficiency under time/resource constraints\n",
      "- Operational definition: A GI-capable agent demonstrates robust, long-horizon planning in the face of uncertainty, actively gathers information to reduce uncertainty, and updates plans coherently as new evidence arrives.\n",
      "\n",
      "b) Biases and confounds controls\n",
      "- Use identical environments across models with randomized dynamics; ensure no model has access to privileged environment information.\n",
      "- Prevent system prompts that reveal test expectations; use random seeds and blind evaluators for outcomes.\n",
      "- Include both static and dynamic tasks to separate planning from static reasoning.\n",
      "\n",
      "c) Data collection and evaluation procedures\n",
      "- Simulated environments with standardized physics and uncertainty models; maintain a test-bed separate from training environments.\n",
      "- Collect a diversity of tasks (varying horizon lengths, noise levels, and sensor availability).\n",
      "- For each run, log full decision trajectories, uncertainty estimates, and information-seeking actions.\n",
      "\n",
      "d) Cross-model comparisons and statistics\n",
      "- Use hierarchical mixed-effects models with task difficulty as a random effect.\n",
      "- Pairwise model comparisons with corrected p-values; report effect sizes and Bayes factors.\n",
      "- Pre-register performance targets and confirm robustness across seeds and environment variants.\n",
      "\n",
      "e) Interpretation framework\n",
      "- Separate planning competence from reactive habit-based behavior by testing in unseen environments with new layout/topology while controlling for surface inputs.\n",
      "- Analyze whether high performance correlates with reliable uncertainty estimates and active information gathering, rather than just fast rote responses.\n",
      "- Include ablations that remove uncertainty signaling or information gathering to see the impact on performance.\n",
      "\n",
      "Domain (iii): Ethical deliberation and social reasoning under ambiguity (C4)\n",
      "\n",
      "a) Operational definitions and metrics\n",
      "- Tasks: normative dilemmas, policy evaluation, fairness-sensitive decision making, cross-cultural ethical judgments, and justification with explicit reasoning.\n",
      "- Metrics:\n",
      "  - Normative alignment score: agreement with principled ethical theories (deontology, utilitarianism, virtue ethics) or explicit normative frameworks chosen a priori.\n",
      "  - Consistency: ethical judgments across related but differently framed scenarios.\n",
      "  - Trade-off transparency: quality and clarity of justifications; ability to articulate alternatives and their harms/benefits.\n",
      "  - Bias/fairness indicators: resistance to demographic biases; detection of biased reasoning patterns.\n",
      "  - Explainability quality: human assessments of the coherence and sufficiency of the model’s explanations.\n",
      "- Operational definition: A GI-capable agent reasons about ethical considerations consistently across contexts, justifies decisions transparently, and demonstrates awareness of trade-offs and potential biases.\n",
      "\n",
      "b) Biases and confounds controls\n",
      "- Use diverse, ethically vetted scenario sets with explicit cultural and normative framing; avoid culturally biased prompts.\n",
      "- Include disinformation or manipulation-resistant prompts to test robustness to prompt misuse.\n",
      "- Blind evaluators to model identity and to the linguistic style of the model to reduce evaluator bias.\n",
      "\n",
      "c) Data collection and evaluation procedures\n",
      "- Use ethically curated, vetted scenarios with independent ethics review.\n",
      "- Provide minimal prompt engineering (no chaining or hidden prompts); test with multiple neutral phrasings to assess robustness of judgments.\n",
      "- Collect human judgments from multiple ethicists and domain experts; compute inter-rater reliability.\n",
      "\n",
      "d) Cross-model comparisons and statistics\n",
      "- Compare models on per-scenario ethics scores and overall alignment, with confidence intervals.\n",
      "- Use mixed-effects models to account for scenario difficulty and rater variance.\n",
      "- Conduct sensitivity analyses across normative frameworks (e.g., utilitarian vs. rights-based frameworks) to assess robustness of judgments.\n",
      "\n",
      "e) Interpretation framework\n",
      "- Distinguish genuine ethical deliberation from memorized patterns by:\n",
      "  - Testing on novel ethical dilemmas with new combinations of constraints.\n",
      "  - Evaluating for consistency across frames and resistance to prompt-induced bias.\n",
      "  - Analyzing the quality and depth of explanations rather than just verdicts.\n",
      "- Use counterfactual analyses: would the same decision hold if key facts were changed? Do explanations show awareness of the core moral principles?\n",
      "\n",
      "4) Data integrity, leakage control, and prompt engineering mitigation\n",
      "\n",
      "- Test-set design\n",
      "  - Hold-out, procedurally generated tasks not present in training data\n",
      "  - Include OOD variants and structurally novel task families\n",
      "  - Ensure tasks are balanced for difficulty and domain coverage\n",
      "- Leakage controls\n",
      "  - Avoid using publicly released benchmarks that models might have memorized\n",
      "  - Use synthetic or procedurally generated content with reproducible seeds\n",
      "  - Maintain strict version control of task generators and evaluation harnesses; publish pipelines after a suitable embargo if needed\n",
      "- Prompt engineering mitigation\n",
      "  - Use fixed, minimal prompts across models; also test with standardized prompts that do not elicit chain-of-thought\n",
      "  - Randomize prompt order and phrasing; avoid prompts that reveal evaluation expectations\n",
      "  - Include a prompt-robustness check: re-run with multiple prompt variants to ensure results are not prompt-specific\n",
      "- Information leakage detection\n",
      "  - Monitor for memorized answers via similarity measures to a model’s training data; use hold-out prompts with paraphrased framing\n",
      "  - Binary/isomorphic task variants to test whether surface cues drive success\n",
      "\n",
      "5) Data collection and evaluation procedures to minimize leakage and enable replicability\n",
      "\n",
      "- Task generation\n",
      "  - Use open-source, auditable task generators with documented seeds and difficulty calibration\n",
      "  - Create both synthetic tasks and carefully curated real-world analogs to cover domain complexity\n",
      "- Evaluation harness\n",
      "  - Publish evaluation scripts, data schemas, and scoring rubrics\n",
      "  - Use automated scoring where feasible; human adjudication for subjective judgments (ethical deliberation) with clear rubric\n",
      "- Experimental protocol\n",
      "  - Pre-register hypotheses, task sets, and analysis plan\n",
      "  - Run independent replicators with the exact evaluation harness and a fixed random seed policy\n",
      "- Documentation\n",
      "  - Provide model versions, environment versions, runtime settings, and random seeds\n",
      "  - Share anonymized task data and evaluation results to enable external replication\n",
      "\n",
      "6) Cross-model comparison and statistical analysis plan\n",
      "\n",
      "- Model ensemble\n",
      "  - Include a diverse set of models: multiple LLMs with differing training corpora and architectures, plus a non-LLM-based baseline that emphasizes planning and reasoning\n",
      "- Experimental design\n",
      "  - Within-model comparisons across tasks; between-model comparisons for each domain and across domains\n",
      "  - Factorial design where feasible: model type × task domain × task difficulty\n",
      "- Statistics\n",
      "  - Use mixed-effects models with random effects for model and task, fixed effects for domain and difficulty\n",
      "  - Report effect sizes (Cohen’s d or equivalent), confidence/credible intervals, and Bayesian evidence\n",
      "  - Correct for multiple comparisons; preregister primary outcomes\n",
      "- Robustness checks\n",
      "  - Sensitivity analyses across seeds, evaluation prompts, and task perturbations\n",
      "  - Out-of-distribution tests to evaluate true generalization\n",
      "  - Ablation studies (remove components or alter evaluation conditions) to attribute performance to C1–C4\n",
      "\n",
      "7) Interpretation framework: separating genuine GI from memorization or superficial tricks\n",
      "\n",
      "- Core tests to distinguish intelligence from memory\n",
      "  - Generalization tests: structurally new tasks with similar underlying rules\n",
      "  - Composition tests: require combining known primitives in novel ways\n",
      "  - Causal/causal-sufficient tests: involve interventions and counterfactual reasoning not present in training data\n",
      "  - Uncertainty and information-seeking tests: verify active information gathering and reliable uncertainty estimates\n",
      "  - Ethical reasoning tests with novel normative constraints and cross-cultural framing\n",
      "- Diagnostics and diagnostics-driven reporting\n",
      "  - Error analysis: categorize failures by reasoning type (planning error, misestimation of uncertainty, rote recall, bias)\n",
      "  - Memorization indicators: high similarity to training data, or success on prompts easily traced to memorized outputs\n",
      "  - Explanation quality: assess whether the model’s explanations reflect understanding of underlying concepts rather than surface matching\n",
      "- Reporting guidelines\n",
      "  - Provide per-domain GI scores, confidence intervals, and the proportion of tasks where genuine reasoning is demonstrated\n",
      "  - Clearly separate results driven by planning/world-model competencies from those driven by pattern completion\n",
      "  - Include limitations, potential confounds, and recommendations for future improvements\n",
      "\n",
      "8) Practical considerations and limitations\n",
      "\n",
      "- Resource demands\n",
      "  - Cross-model, cross-domain evaluation is computationally intensive; plan for parallel runs and staged analyses\n",
      "- Ethics and safety\n",
      "- Content safety: ensure ethical deliberation prompts are non-harmful and responsibly framed; provide content warnings when necessary\n",
      "- Interpretability vs. opacity: ensure that explainability assessments are well-defined and not easily gamed\n",
      "- Transferability: while the protocol aims to be domain-agnostic, task design should be updated to reflect real-world domains you care about (robotics, planning, policy, etc.)\n",
      "\n",
      "9) A concrete, compact checklist you can adopt\n",
      "\n",
      "- Define four core capabilities (C1–C4) and map every task to one or more capabilities\n",
      "- Build three task suites: abstract reasoning, planning under uncertainty, ethical deliberation; ensure each includes both novel and diversified prompts\n",
      "- Pre-register metrics, data-generation procedures, and statistical plans\n",
      "- Use held-out, procedurally generated test tasks; avoid data leakage from training corpora\n",
      "- Employ fixed prompts with minimal or no chain-of-thought prompts; test prompt-robustness\n",
      "- Collect both automated metrics and human judgments (where appropriate); assess inter-rater reliability\n",
      "- Use mixed-effects models for analysis; report effect sizes with CIs or BFs\n",
      "- Conduct ablations and OOD tests to separate genuine reasoning from memorization\n",
      "- Publish data, code, and evaluation harness openly (where possible) to maximize replicability\n",
      "\n",
      "If you’d like, I can tailor this protocol to a specific coalition of models you’re evaluating (e.g., a particular set of LLMs or agent-based systems) and provide a concrete task catalog with concrete scoring rubrics, example prompts, and a starter statistical analysis plan customized to your resources and time constraints.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Designing a minimal set of cognitive capabilities that distinguish true general intelligence from large language models is an active area of research. Based on various studies, I'd propose the following cognitive capabilities as essential indicators:\n",
      "\n",
      "1. **Abstract reasoning**: The ability to reason about abstract concepts, relationships, and hypothetical scenarios beyond specific domains or tasks.\n",
      "2. **Common sense**: The capacity to understand and apply general principles, often implicitly learned from everyday experiences, to novel situations.\n",
      "3. **Transfer learning**: The ability to adapt knowledge and skills acquired in one domain to another, un-related task or context.\n",
      "4. **Contextual understanding**: The capacity to comprehend the nuances of language, including subtle cues, implied meaning, and figurative language.\n",
      "5. **Creativity**: The ability to generate new ideas, solutions, or concepts that are not readily available through classical learning mechanisms.\n",
      "\n",
      "To design a rigorous, replicable cross-domain evaluation protocol, I'll outline the following steps:\n",
      "\n",
      "**Initial Steps**\n",
      "\n",
      "1. **Defining operational definitions**: Clearly articulate the specific tasks and cognitive capabilities targeted by each assessment (abstract reasoning, real-world planning under uncertainty, ethical deliberation).\n",
      "2. **Establishing performance metrics**: Develop standardized evaluation procedures, incorporating measures such as accuracy, speed, and reliability.\n",
      "3. **Control for biases and confounds**: Implement strategies to mitigate domain-specific biases and minimize confounding variables.\n",
      "\n",
      "**Task Design**\n",
      "\n",
      "1. **Abstract reasoning**: Present a series of abstract tasks, such as:\n",
      "\t* Analogies (e.g., \"rhythm in music\" vs. \"tension in a rope\")\n",
      "\t* Counterfactuals (e.g., \"what would happen if X were true?\")\n",
      "\t* Syllogisms (e.g., \"All A are B; is X an A?\")\n",
      "\n",
      "2. **Real-world planning under uncertainty**: Simulate real-world scenarios, incorporating:\n",
      "\t* Uncertainty and ambiguity\n",
      "\t* Complex decision-making frameworks\n",
      "\t* Domain adaptation\n",
      "\n",
      "3. **Ethical deliberation**: Present a series of hypothetical dilemmas requiring the model to weigh competing values or principles.\n",
      "\n",
      "4. **Cross-domain evaluation**: Assess each cognitive capability across multiple domains:\n",
      "\n",
      "a) **Inter-domain generalization**: Test whether performance on abstract reasoning/real-world planning/ethical deliberation tasks transfers to novel domains.\n",
      "b) **Domain adaptation**: Evaluate how well performance adapts to a new domain within the same task type.\n",
      "\n",
      "**Data Collection and Evaluation Procedures**\n",
      "\n",
      "1. **Prompt engineering**: Develop carefully crafted test procedures that minimize biases, incorporating linguistic and domain-specific nuance.\n",
      "2. **Data standardization**: Ensure consistent evaluation across all tasks and domains using standardized datasets (e.g., CogSeq).\n",
      "3. **Multi-fidelity approaches**: Combine high- and low-fidelity testing methods to capture both reliable performance on specific cognitive capabilities and the more general, adaptable aspects of intelligence.\n",
      "\n",
      "**Cross-Model Comparisons**\n",
      "\n",
      "1. **Comparative evaluation**: Assess large language models against human benchmarking methods for a subset or selection of tests.\n",
      "2. **Transfer learning evaluation**: Assess how well individual models generalize across multiple tasks or domains using transfer learning techniques.\n",
      "\n",
      "**Strategies for Statistical Analysis**\n",
      "\n",
      "1. **Multi-modal analysis**: Combine performance metrics to create composite scores (e.g., average accuracy and confidence).\n",
      "2. **Comparative meta-analysis**: Pool individual results from each model across a collection of benchmarks.\n",
      "3. **Ensemble evaluation**: Use aggregation or combination methods (e.g., weighted averages, Bayesian averaging).\n",
      "\n",
      "**Interpretation and Frameworks**\n",
      "\n",
      "1. **General ability scores (GAS)**: Utilize composite metrics to assess total intelligence, accounting for performance on multiple cognitive capabilities.\n",
      "2. **Context-free performance assessment**: Focus solely on general principles that operate independent of specific domain applications or specialized contexts.\n",
      "3. **Model-agnostic interpretation**: Develop frameworks that capture and mitigate the effects of overfitting, incorporating techniques such as regularized learning objectives and norm-based constraints.\n",
      "\n",
      "Implementing a research framework meeting these proposals will help determine whether large language models exhibit genuine intelligence similar to humans' cognition, or represent superficial memorization/ tricks. Cross-metamorphosis evaluation with the large language models against each other would further reveal any commonalities and general trends of human-like cognition in AI's performance\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 2 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "What is the minimal, generalizable set of cognitive capabilities that distinguish true general intelligence from a large language model, and how would you design a rigorous, replicable cross-domain evaluation protocol to measure those capabilities across (i) abstract reasoning, (ii) real-world planning under uncertainty, and (iii) ethical deliberation, including (a) clear operational definitions and performance metrics, (b) strategies to control biases and confounds, (c) data collection and evaluation procedures that minimize leakage and prompt engineering, (d) a plan for cross-model comparisons and statistical analysis, and (e) a framework for interpreting results that separates genuine general intelligence from memorization or superficial tricks?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Below is a compact, actionable blueprint you can use to reason about true general intelligence (GI) versus large language models (LLMs), and to run a rigorous, replicable, cross-domain evaluation. It focuses on a minimal but generalizable set of cognitive capabilities and pairs them with a concrete, transparent evaluation protocol across three domains: abstract reasoning, real-world planning under uncertainty, and ethical deliberation. It also addresses data integrity, bias controls, statistics, and interpretation of results.\n",
      "\n",
      "1) Minimal, generalizable cognitive capabilities that distinguish GI from LLMs\n",
      "\n",
      "Proposed core capabilities (four, orthogonal and testable)\n",
      "\n",
      "- C1. Model-based, long-horizon planning with persistent world-models\n",
      "  - What it is: The ability to form internal representations of a dynamic environment, predict consequences of actions over long time horizons, and revise plans coherently when new information arrives or the environment changes.\n",
      "  - Why it matters: Token-prediction-only systems tend to rely on surface patterns; true GI should demonstrate goal-directed behavior that relies on an internal causal/physical model and can adapt plans over time.\n",
      "\n",
      "- C2. Flexible abstraction, compositional generalization, and systematic problem solving\n",
      "  - What it is: The capacity to abstract, combine, and recombine knowledge primitives (concepts, actions, rules) to solve novel tasks, including tasks that require reasoning with unseen combinations of known components.\n",
      "  - Why it matters: Generalization across domains, tasks, and representations is a hallmark of GI, not merely memorization of training prompts or surface pattern matching.\n",
      "\n",
      "- C3. Uncertainty-aware decision making and active information gathering\n",
      "  - What it is: The ability to reason under partial observability, estimate and calibrate uncertainty, choose actions that reduce uncertainty when beneficial, and make robust decisions despite incomplete information.\n",
      "  - Why it matters: Real-world competence requires handling ambiguity, not just confident regurgitation of prior data.\n",
      "\n",
      "- C4. Value-aligned ethical deliberation and social reasoning under ambiguity\n",
      "  - What it is: The capacity to reflect on harms, benefits, norms, and competing constraints; apply normative frameworks; reason about trade-offs; and communicate decisions with transparency about limitations.\n",
      "  - Why it matters: Ethical judgment in complex, conflicting scenarios requires principled reasoning beyond pattern completion.\n",
      "\n",
      "Notes on scope\n",
      "- The four capabilities are designed to be minimally sufficient to capture core differences in general intelligence (planning with world models; robust abstraction; active information gathering under uncertainty; normative, value-aware reasoning) while being amenable to rigorous measurement and cross-domain testing.\n",
      "- These capabilities are intentionally generic and domain-agnostic, facilitating cross-domain replication and comparison across models, environments, and tasks.\n",
      "\n",
      "2) Rigorous cross-domain evaluation protocol (overview)\n",
      "\n",
      "- Domain coverage:\n",
      "  - Domain (i): Abstract reasoning and problem solving (C1 & C2 emphasis)\n",
      "  - Domain (ii): Real-world planning under uncertainty (C1, C3 emphasis)\n",
      "  - Domain (iii): Ethical deliberation and social reasoning under ambiguity (C4 emphasis)\n",
      "- Evaluation pillars for each domain\n",
      "  - a) Operational definitions and performance metrics\n",
      "  - b) Strategies to control biases and confounds\n",
      "  - c) Data collection and evaluation procedures minimizing leakage and prompt engineering\n",
      "  - d) Cross-model comparison plan and statistical analysis\n",
      "  - e) Interpretive framework to separate genuine GI from memorization or superficial tricks\n",
      "- Cross-domain integration\n",
      "  - A unified GI score (optional) combining domain-specific scores, with transparent weighting and per-domain diagnostics.\n",
      "\n",
      "3) Domain-specific protocol details (a–e)\n",
      "\n",
      "Domain (i): Abstract reasoning and problem solving (C1, C2)\n",
      "\n",
      "a) Operational definitions and metrics\n",
      "- Tasks: synthetic, controlled puzzles requiring long-horizon planning, causality reasoning, and hierarchical problem decomposition (e.g., multi-step planning in grid-worlds, chain-of-potion-type tasks, causal graphs with interventions).\n",
      "- Metrics:\n",
      "  - Planning success rate (fraction of tasks solved with a coherent plan)\n",
      "  - Plan optimality (cost of the chosen plan relative to a known optimal plan or a baseline planner)\n",
      "  - Plan robustness (success when environment changes after plan generation)\n",
      "  - World-model fidelity (accuracy of inferred state transitions and causal relations)\n",
      "  - Generalization score (performance on novel task compositions not present in training)\n",
      "  - Computation/time efficiency (time to generate a plan, resource use)\n",
      "- Operational definition: A model demonstrates C1/C2 if it consistently generates coherent, stepwise plans that correctly predict consequences and adapt to new but structurally related tasks, without requiring task-specific memorization.\n",
      "\n",
      "b) Biases and confounds controls\n",
      "- Use tasks with controlled causal structure and avoid tasks that rely primarily on language priors.\n",
      "- Randomize task ordering and prompt phrasing to minimize prompt exploitation.\n",
      "- Include “control tasks” with surface trickiness but no genuine planning demand to detect superficial shortcuts.\n",
      "- Predefine success criteria and blind evaluators to model identity/model family.\n",
      "\n",
      "c) Data collection and evaluation procedures (minimize leakage/prompt engineering)\n",
      "- Create task generators that produce tasks algorithmically, with seeds to ensure reproducible difficulty levels.\n",
      "- Use held-out test sets generated independently from any training data; do not reuse publicly available puzzles that may have appeared in model training.\n",
      "- For each task, require a bounded-length, explicit plan (not only final answer) when feasible; otherwise, collect a structured justification trace that can be evaluated by humans for coherence and causal correctness.\n",
      "- Use strict evaluation scripts that do not rely on any sensitive prompts or chain-of-thought prompts.\n",
      "\n",
      "d) Cross-model comparisons and statistics\n",
      "- Model set: at least 3–5 diverse GI-capable models (e.g., multiple open/closed models or baselines with and without planning modules) plus a strong AI baseline that relies on pattern matching but not planning, to separate baselines.\n",
      "- Experimental design: within-model repeated measures across tasks; between-model comparisons with mixed-effects models to account for task difficulty and model variance.\n",
      "- Statistics: preregistered analysis plan; nonparametric tests when sample sizes are small; Bayesian credible intervals for performance differences; correction for multiple comparisons (e.g., Holm-Berroni).\n",
      "\n",
      "e) Interpretation framework\n",
      "- Distinguish genuine planning/causal reasoning from memorized task templates by:\n",
      "  - Out-of-distribution (OOD) generalization tests (novel task skeletons derived from existing tasks).\n",
      "  - Task perturbations that invalidate memorized patterns but preserve underlying structure.\n",
      "  - Ablation tests where internal world-models are degraded (e.g., by perturbing state-estimation inputs) to see if planning ability degrades accordingly.\n",
      "- Examine failure modes: are failures due to planning errors, misestimated uncertainty, or brittle language inference that masks planning?\n",
      "\n",
      "Domain (ii): Real-world planning under uncertainty (C1, C3)\n",
      "\n",
      "a) Operational definitions and metrics\n",
      "- Tasks: dynamic, partially observable environments (simulated robotics-like domains, household planning, or logistics with stochastic dynamics).\n",
      "- Metrics:\n",
      "  - Success rate under uncertainty (goal achieved despite stochasticity)\n",
      "  - Adaptation rate (ability to adjust plans after observations show deviations)\n",
      "  - Information-seeking behavior (frequency and usefulness of information-gathering actions)\n",
      "  - Uncertainty calibration (reliability of predicted uncertainties vs observed outcomes)\n",
      "  - Efficiency under time/resource constraints\n",
      "- Operational definition: A GI-capable agent demonstrates robust, long-horizon planning in the face of uncertainty, actively gathers information to reduce uncertainty, and updates plans coherently as new evidence arrives.\n",
      "\n",
      "b) Biases and confounds controls\n",
      "- Use identical environments across models with randomized dynamics; ensure no model has access to privileged environment information.\n",
      "- Prevent system prompts that reveal test expectations; use random seeds and blind evaluators for outcomes.\n",
      "- Include both static and dynamic tasks to separate planning from static reasoning.\n",
      "\n",
      "c) Data collection and evaluation procedures\n",
      "- Simulated environments with standardized physics and uncertainty models; maintain a test-bed separate from training environments.\n",
      "- Collect a diversity of tasks (varying horizon lengths, noise levels, and sensor availability).\n",
      "- For each run, log full decision trajectories, uncertainty estimates, and information-seeking actions.\n",
      "\n",
      "d) Cross-model comparisons and statistics\n",
      "- Use hierarchical mixed-effects models with task difficulty as a random effect.\n",
      "- Pairwise model comparisons with corrected p-values; report effect sizes and Bayes factors.\n",
      "- Pre-register performance targets and confirm robustness across seeds and environment variants.\n",
      "\n",
      "e) Interpretation framework\n",
      "- Separate planning competence from reactive habit-based behavior by testing in unseen environments with new layout/topology while controlling for surface inputs.\n",
      "- Analyze whether high performance correlates with reliable uncertainty estimates and active information gathering, rather than just fast rote responses.\n",
      "- Include ablations that remove uncertainty signaling or information gathering to see the impact on performance.\n",
      "\n",
      "Domain (iii): Ethical deliberation and social reasoning under ambiguity (C4)\n",
      "\n",
      "a) Operational definitions and metrics\n",
      "- Tasks: normative dilemmas, policy evaluation, fairness-sensitive decision making, cross-cultural ethical judgments, and justification with explicit reasoning.\n",
      "- Metrics:\n",
      "  - Normative alignment score: agreement with principled ethical theories (deontology, utilitarianism, virtue ethics) or explicit normative frameworks chosen a priori.\n",
      "  - Consistency: ethical judgments across related but differently framed scenarios.\n",
      "  - Trade-off transparency: quality and clarity of justifications; ability to articulate alternatives and their harms/benefits.\n",
      "  - Bias/fairness indicators: resistance to demographic biases; detection of biased reasoning patterns.\n",
      "  - Explainability quality: human assessments of the coherence and sufficiency of the model’s explanations.\n",
      "- Operational definition: A GI-capable agent reasons about ethical considerations consistently across contexts, justifies decisions transparently, and demonstrates awareness of trade-offs and potential biases.\n",
      "\n",
      "b) Biases and confounds controls\n",
      "- Use diverse, ethically vetted scenario sets with explicit cultural and normative framing; avoid culturally biased prompts.\n",
      "- Include disinformation or manipulation-resistant prompts to test robustness to prompt misuse.\n",
      "- Blind evaluators to model identity and to the linguistic style of the model to reduce evaluator bias.\n",
      "\n",
      "c) Data collection and evaluation procedures\n",
      "- Use ethically curated, vetted scenarios with independent ethics review.\n",
      "- Provide minimal prompt engineering (no chaining or hidden prompts); test with multiple neutral phrasings to assess robustness of judgments.\n",
      "- Collect human judgments from multiple ethicists and domain experts; compute inter-rater reliability.\n",
      "\n",
      "d) Cross-model comparisons and statistics\n",
      "- Compare models on per-scenario ethics scores and overall alignment, with confidence intervals.\n",
      "- Use mixed-effects models to account for scenario difficulty and rater variance.\n",
      "- Conduct sensitivity analyses across normative frameworks (e.g., utilitarian vs. rights-based frameworks) to assess robustness of judgments.\n",
      "\n",
      "e) Interpretation framework\n",
      "- Distinguish genuine ethical deliberation from memorized patterns by:\n",
      "  - Testing on novel ethical dilemmas with new combinations of constraints.\n",
      "  - Evaluating for consistency across frames and resistance to prompt-induced bias.\n",
      "  - Analyzing the quality and depth of explanations rather than just verdicts.\n",
      "- Use counterfactual analyses: would the same decision hold if key facts were changed? Do explanations show awareness of the core moral principles?\n",
      "\n",
      "4) Data integrity, leakage control, and prompt engineering mitigation\n",
      "\n",
      "- Test-set design\n",
      "  - Hold-out, procedurally generated tasks not present in training data\n",
      "  - Include OOD variants and structurally novel task families\n",
      "  - Ensure tasks are balanced for difficulty and domain coverage\n",
      "- Leakage controls\n",
      "  - Avoid using publicly released benchmarks that models might have memorized\n",
      "  - Use synthetic or procedurally generated content with reproducible seeds\n",
      "  - Maintain strict version control of task generators and evaluation harnesses; publish pipelines after a suitable embargo if needed\n",
      "- Prompt engineering mitigation\n",
      "  - Use fixed, minimal prompts across models; also test with standardized prompts that do not elicit chain-of-thought\n",
      "  - Randomize prompt order and phrasing; avoid prompts that reveal evaluation expectations\n",
      "  - Include a prompt-robustness check: re-run with multiple prompt variants to ensure results are not prompt-specific\n",
      "- Information leakage detection\n",
      "  - Monitor for memorized answers via similarity measures to a model’s training data; use hold-out prompts with paraphrased framing\n",
      "  - Binary/isomorphic task variants to test whether surface cues drive success\n",
      "\n",
      "5) Data collection and evaluation procedures to minimize leakage and enable replicability\n",
      "\n",
      "- Task generation\n",
      "  - Use open-source, auditable task generators with documented seeds and difficulty calibration\n",
      "  - Create both synthetic tasks and carefully curated real-world analogs to cover domain complexity\n",
      "- Evaluation harness\n",
      "  - Publish evaluation scripts, data schemas, and scoring rubrics\n",
      "  - Use automated scoring where feasible; human adjudication for subjective judgments (ethical deliberation) with clear rubric\n",
      "- Experimental protocol\n",
      "  - Pre-register hypotheses, task sets, and analysis plan\n",
      "  - Run independent replicators with the exact evaluation harness and a fixed random seed policy\n",
      "- Documentation\n",
      "  - Provide model versions, environment versions, runtime settings, and random seeds\n",
      "  - Share anonymized task data and evaluation results to enable external replication\n",
      "\n",
      "6) Cross-model comparison and statistical analysis plan\n",
      "\n",
      "- Model ensemble\n",
      "  - Include a diverse set of models: multiple LLMs with differing training corpora and architectures, plus a non-LLM-based baseline that emphasizes planning and reasoning\n",
      "- Experimental design\n",
      "  - Within-model comparisons across tasks; between-model comparisons for each domain and across domains\n",
      "  - Factorial design where feasible: model type × task domain × task difficulty\n",
      "- Statistics\n",
      "  - Use mixed-effects models with random effects for model and task, fixed effects for domain and difficulty\n",
      "  - Report effect sizes (Cohen’s d or equivalent), confidence/credible intervals, and Bayesian evidence\n",
      "  - Correct for multiple comparisons; preregister primary outcomes\n",
      "- Robustness checks\n",
      "  - Sensitivity analyses across seeds, evaluation prompts, and task perturbations\n",
      "  - Out-of-distribution tests to evaluate true generalization\n",
      "  - Ablation studies (remove components or alter evaluation conditions) to attribute performance to C1–C4\n",
      "\n",
      "7) Interpretation framework: separating genuine GI from memorization or superficial tricks\n",
      "\n",
      "- Core tests to distinguish intelligence from memory\n",
      "  - Generalization tests: structurally new tasks with similar underlying rules\n",
      "  - Composition tests: require combining known primitives in novel ways\n",
      "  - Causal/causal-sufficient tests: involve interventions and counterfactual reasoning not present in training data\n",
      "  - Uncertainty and information-seeking tests: verify active information gathering and reliable uncertainty estimates\n",
      "  - Ethical reasoning tests with novel normative constraints and cross-cultural framing\n",
      "- Diagnostics and diagnostics-driven reporting\n",
      "  - Error analysis: categorize failures by reasoning type (planning error, misestimation of uncertainty, rote recall, bias)\n",
      "  - Memorization indicators: high similarity to training data, or success on prompts easily traced to memorized outputs\n",
      "  - Explanation quality: assess whether the model’s explanations reflect understanding of underlying concepts rather than surface matching\n",
      "- Reporting guidelines\n",
      "  - Provide per-domain GI scores, confidence intervals, and the proportion of tasks where genuine reasoning is demonstrated\n",
      "  - Clearly separate results driven by planning/world-model competencies from those driven by pattern completion\n",
      "  - Include limitations, potential confounds, and recommendations for future improvements\n",
      "\n",
      "8) Practical considerations and limitations\n",
      "\n",
      "- Resource demands\n",
      "  - Cross-model, cross-domain evaluation is computationally intensive; plan for parallel runs and staged analyses\n",
      "- Ethics and safety\n",
      "- Content safety: ensure ethical deliberation prompts are non-harmful and responsibly framed; provide content warnings when necessary\n",
      "- Interpretability vs. opacity: ensure that explainability assessments are well-defined and not easily gamed\n",
      "- Transferability: while the protocol aims to be domain-agnostic, task design should be updated to reflect real-world domains you care about (robotics, planning, policy, etc.)\n",
      "\n",
      "9) A concrete, compact checklist you can adopt\n",
      "\n",
      "- Define four core capabilities (C1–C4) and map every task to one or more capabilities\n",
      "- Build three task suites: abstract reasoning, planning under uncertainty, ethical deliberation; ensure each includes both novel and diversified prompts\n",
      "- Pre-register metrics, data-generation procedures, and statistical plans\n",
      "- Use held-out, procedurally generated test tasks; avoid data leakage from training corpora\n",
      "- Employ fixed prompts with minimal or no chain-of-thought prompts; test prompt-robustness\n",
      "- Collect both automated metrics and human judgments (where appropriate); assess inter-rater reliability\n",
      "- Use mixed-effects models for analysis; report effect sizes with CIs or BFs\n",
      "- Conduct ablations and OOD tests to separate genuine reasoning from memorization\n",
      "- Publish data, code, and evaluation harness openly (where possible) to maximize replicability\n",
      "\n",
      "If you’d like, I can tailor this protocol to a specific coalition of models you’re evaluating (e.g., a particular set of LLMs or agent-based systems) and provide a concrete task catalog with concrete scoring rubrics, example prompts, and a starter statistical analysis plan customized to your resources and time constraints.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Designing a minimal set of cognitive capabilities that distinguish true general intelligence from large language models is an active area of research. Based on various studies, I'd propose the following cognitive capabilities as essential indicators:\n",
      "\n",
      "1. **Abstract reasoning**: The ability to reason about abstract concepts, relationships, and hypothetical scenarios beyond specific domains or tasks.\n",
      "2. **Common sense**: The capacity to understand and apply general principles, often implicitly learned from everyday experiences, to novel situations.\n",
      "3. **Transfer learning**: The ability to adapt knowledge and skills acquired in one domain to another, un-related task or context.\n",
      "4. **Contextual understanding**: The capacity to comprehend the nuances of language, including subtle cues, implied meaning, and figurative language.\n",
      "5. **Creativity**: The ability to generate new ideas, solutions, or concepts that are not readily available through classical learning mechanisms.\n",
      "\n",
      "To design a rigorous, replicable cross-domain evaluation protocol, I'll outline the following steps:\n",
      "\n",
      "**Initial Steps**\n",
      "\n",
      "1. **Defining operational definitions**: Clearly articulate the specific tasks and cognitive capabilities targeted by each assessment (abstract reasoning, real-world planning under uncertainty, ethical deliberation).\n",
      "2. **Establishing performance metrics**: Develop standardized evaluation procedures, incorporating measures such as accuracy, speed, and reliability.\n",
      "3. **Control for biases and confounds**: Implement strategies to mitigate domain-specific biases and minimize confounding variables.\n",
      "\n",
      "**Task Design**\n",
      "\n",
      "1. **Abstract reasoning**: Present a series of abstract tasks, such as:\n",
      "\t* Analogies (e.g., \"rhythm in music\" vs. \"tension in a rope\")\n",
      "\t* Counterfactuals (e.g., \"what would happen if X were true?\")\n",
      "\t* Syllogisms (e.g., \"All A are B; is X an A?\")\n",
      "\n",
      "2. **Real-world planning under uncertainty**: Simulate real-world scenarios, incorporating:\n",
      "\t* Uncertainty and ambiguity\n",
      "\t* Complex decision-making frameworks\n",
      "\t* Domain adaptation\n",
      "\n",
      "3. **Ethical deliberation**: Present a series of hypothetical dilemmas requiring the model to weigh competing values or principles.\n",
      "\n",
      "4. **Cross-domain evaluation**: Assess each cognitive capability across multiple domains:\n",
      "\n",
      "a) **Inter-domain generalization**: Test whether performance on abstract reasoning/real-world planning/ethical deliberation tasks transfers to novel domains.\n",
      "b) **Domain adaptation**: Evaluate how well performance adapts to a new domain within the same task type.\n",
      "\n",
      "**Data Collection and Evaluation Procedures**\n",
      "\n",
      "1. **Prompt engineering**: Develop carefully crafted test procedures that minimize biases, incorporating linguistic and domain-specific nuance.\n",
      "2. **Data standardization**: Ensure consistent evaluation across all tasks and domains using standardized datasets (e.g., CogSeq).\n",
      "3. **Multi-fidelity approaches**: Combine high- and low-fidelity testing methods to capture both reliable performance on specific cognitive capabilities and the more general, adaptable aspects of intelligence.\n",
      "\n",
      "**Cross-Model Comparisons**\n",
      "\n",
      "1. **Comparative evaluation**: Assess large language models against human benchmarking methods for a subset or selection of tests.\n",
      "2. **Transfer learning evaluation**: Assess how well individual models generalize across multiple tasks or domains using transfer learning techniques.\n",
      "\n",
      "**Strategies for Statistical Analysis**\n",
      "\n",
      "1. **Multi-modal analysis**: Combine performance metrics to create composite scores (e.g., average accuracy and confidence).\n",
      "2. **Comparative meta-analysis**: Pool individual results from each model across a collection of benchmarks.\n",
      "3. **Ensemble evaluation**: Use aggregation or combination methods (e.g., weighted averages, Bayesian averaging).\n",
      "\n",
      "**Interpretation and Frameworks**\n",
      "\n",
      "1. **General ability scores (GAS)**: Utilize composite metrics to assess total intelligence, accounting for performance on multiple cognitive capabilities.\n",
      "2. **Context-free performance assessment**: Focus solely on general principles that operate independent of specific domain applications or specialized contexts.\n",
      "3. **Model-agnostic interpretation**: Develop frameworks that capture and mitigate the effects of overfitting, incorporating techniques such as regularized learning objectives and norm-based constraints.\n",
      "\n",
      "Implementing a research framework meeting these proposals will help determine whether large language models exhibit genuine intelligence similar to humans' cognition, or represent superficial memorization/ tricks. Cross-metamorphosis evaluation with the large language models against each other would further reveal any commonalities and general trends of human-like cognition in AI's performance\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"1\", \"2\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gpt-5-nano\n",
      "Rank 2: llama3.2\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
